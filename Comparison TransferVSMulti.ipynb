{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "24b75a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "from rate import *\n",
    "\n",
    "from sklearn.datasets import make_friedman2\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel, RBF, Matern, RationalQuadratic, ExpSineSquared\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, QuantileTransformer\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from math import sqrt\n",
    "\n",
    "from tensorflow.keras.layers import TimeDistributed, Attention, Input, Conv1D, MaxPooling1D, LSTM, Dense, Flatten, BatchNormalization, Concatenate\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9564a95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_means_variances(y_true, y_means, y_stddevs):\n",
    "    plt.rc('font', size=14)\n",
    "    min_vals = np.min([np.min(y_true), np.min(y_means)])\n",
    "    max_vals = np.max([np.max(y_true), np.max(y_means)])\n",
    "\n",
    "    plt.figure(figsize=(16, 6))\n",
    "\n",
    "    # Plot predicted vs true\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(y_true, y_means, alpha = .7, color=\"0.3\", linewidth = 0, s = 2)\n",
    "    plt.plot([min_vals, max_vals], [min_vals, max_vals], 'k--', color='red')  # Add diagonal line\n",
    "    plt.title('Fig (a): Predicted vs True Values')\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    \n",
    "    def plot_binned_residuals(y_true, residuals, num_bins=20):\n",
    "        bins = np.linspace(min(y_true), max(y_true), num_bins + 1)\n",
    "\n",
    "        bin_means = [0]*num_bins\n",
    "        bin_stddevs = [0]*num_bins\n",
    "\n",
    "        for i in range(num_bins):\n",
    "            mask = (y_true >= bins[i]) & (y_true < bins[i + 1])\n",
    "            if np.any(mask):\n",
    "                bin_means[i] = np.mean(y_true[mask])\n",
    "                bin_stddevs[i] = np.sqrt(mean_squared_error(y_means[mask], y_true[mask]))\n",
    "        return bin_means, bin_stddevs\n",
    "\n",
    "    bin_means, bin_stddevs = plot_binned_residuals(y_true, y_means, num_bins=20)\n",
    "    \n",
    "    # Plot residuals vs true\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(y_true, y_stddevs, alpha = .7, color=\"0.3\", linewidth = 0, s = 2, label='Predicted Standard Deviation', zorder=1)\n",
    "    plt.scatter(bin_means, bin_stddevs, alpha=1, s=50, color='red', label='True Binned Root Mean Squared Error', zorder=2)\n",
    "    plt.title('Fig (b): Predicted Standard Deviation vs True RMSE')\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predicted Standard Deviation')\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def evaluate_and_print_metrics(results, model_name, y_train, y_test, y_train_pred, y_test_pred, y_train_stddevs, y_test_stddevs, ci):\n",
    "    z_value = stats.norm.ppf((1 + ci) / 2)\n",
    "    \n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)    # in %\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)       # in %\n",
    "\n",
    "    train_lower_bound = y_train_pred - z_value * y_train_stddevs\n",
    "    train_upper_bound = y_train_pred + z_value * y_train_stddevs\n",
    "\n",
    "    test_lower_bound = y_test_pred - z_value * y_test_stddevs\n",
    "    test_upper_bound = y_test_pred + z_value * y_test_stddevs\n",
    "\n",
    "    train_within_interval = np.sum(np.logical_and(y_train.ravel() >= train_lower_bound, y_train.ravel() <= train_upper_bound))\n",
    "    test_within_interval = np.sum(np.logical_and(y_test.ravel() >= test_lower_bound, y_test.ravel() <= test_upper_bound))\n",
    "\n",
    "    train_percentage_within_interval = (train_within_interval / len(y_train.ravel())) * 100\n",
    "    test_percentage_within_interval = (test_within_interval / len(y_test.ravel())) * 100\n",
    "\n",
    "   \n",
    "    results[model_name] = {\n",
    "        \"Test Root Mean Squared Error (RMSE): \": test_rmse,\n",
    "        \"Test Mean Absolute Error (MAE): \": test_mae,\n",
    "        f\"Percentage of Test Data Points within {ci*100:.2f}% CI: \": test_percentage_within_interval\n",
    "    }\n",
    "\n",
    "    print(f\"Train RMSE: {train_rmse:.3f}\")\n",
    "    print(f\"Test RMSE: {test_rmse:.3f}\")\n",
    "    print(f\"Train MAE: {train_mae:.3f}\")\n",
    "    print(f\"Test MAE: {test_mae:.3f}\")\n",
    "    print(f\"Percentage of Train Data Points within {ci*100:.2f}% CI: {train_percentage_within_interval:.2f}%\")\n",
    "    print(f\"Percentage of Test Data Points within {ci*100:.2f}% CI: {test_percentage_within_interval:.2f}%\")\n",
    "\n",
    "def plot_confidence_interval_scatter(y_test_pred, y_test_std, y_test, bins=20):\n",
    "    plt.rc('font', size=14)\n",
    "    \n",
    "    # Compute the t-values of the confidence intervals based on Z-scores\n",
    "    t_values = np.array([stats.norm.ppf(i/bins + (1-i/bins)/2) for i in range(1, bins+1)])\n",
    "\n",
    "    percentages_within_interval = []\n",
    "    for t_value in t_values:\n",
    "        lower_bounds = y_test_pred.ravel() - t_value * y_test_std\n",
    "        upper_bounds = y_test_pred.ravel() + t_value * y_test_std\n",
    "\n",
    "        # Count number of data points within the confidence interval\n",
    "        is_within_interval = np.logical_and(y_test >= lower_bounds, y_test <= upper_bounds)\n",
    "        num_within_interval = np.sum(is_within_interval)\n",
    "\n",
    "        # Calculate the percentage of data points within the confidence interval\n",
    "        percentage_within_interval = (num_within_interval / len(y_test)) * 100\n",
    "        percentages_within_interval.append(percentage_within_interval)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(np.arange(1, bins+1), percentages_within_interval, color='blue', label='Percentage within Interval')\n",
    "    \n",
    "    # Plot the expected diagonal line (red line)\n",
    "    plt.plot([0, bins+1], [0, 100], color='red', linestyle='--', label='Expected Diagonal Line')\n",
    "\n",
    "    plt.xlabel('Confidence Intervals')\n",
    "    plt.ylabel('Percentage within Interval')\n",
    "    plt.title('Scatter Plot of Percentage of Data Points within Confidence Intervals')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def load_dataset_train_test_split(df, features, output_feature):\n",
    "    keras.utils.set_random_seed(812)\n",
    "    X = df[features]\n",
    "    y = df[output_feature]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "    # Scale input data to facilitate training\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, np.array(y_train), np.array(y_test), scaler\n",
    "    \n",
    "def train_model(model, X_train, y_train, patience, epochs, batch_size, cp_callback):\n",
    "    tf.random.set_seed(MODELS_SEED)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    model.summary()\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[early_stopping, cp_callback])\n",
    "    return history\n",
    "\n",
    "def plot_loss_history(history):\n",
    "    plt.plot(history.history['loss'][1:], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'][1:], label='Validation Loss', color='red')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def compute_predictions(model, X_train, X_test, num_samples=100):\n",
    "    y_train_pred = []\n",
    "    y_test_pred = []\n",
    "    for _ in range(num_samples):\n",
    "        y_train_pred.append(model.predict(X_train))\n",
    "        y_test_pred.append(model.predict(X_test))\n",
    "        \n",
    "    y_train_pred = np.concatenate(y_train_pred, axis=1)\n",
    "    y_test_pred = np.concatenate(y_test_pred, axis=1)\n",
    "\n",
    "    y_train_pred_mean = np.mean(y_train_pred, axis=1)\n",
    "    y_train_pred_stddevs = np.std(y_train_pred, axis=1)\n",
    "    \n",
    "    y_test_pred_mean = np.mean(y_test_pred, axis=1)\n",
    "    y_test_pred_stddevs = np.std(y_test_pred, axis=1)\n",
    "    \n",
    "    return y_train_pred_mean, y_train_pred_stddevs, y_test_pred_mean, y_test_pred_stddevs\n",
    "\n",
    "def NLL(y, distr): \n",
    "    return -distr.log_prob(y) \n",
    "\n",
    "# We add 0.001 to the standard deviation to ensure it does not converge to 0 and destabilizes training because the gradient\n",
    "# of maximum likelihood estimation requires the inversion of the variance. We also activate the parameters using a softplus\n",
    "# activation function to enfore a positive standard deviation estimate.\n",
    "def normal_softplus(params): \n",
    "    return tfd.Normal(loc=params[:, 0:1], scale=1e-3 + tf.math.softplus(0.05 * params[:, 1:2]))\n",
    "\n",
    "def multivariate_covariance_normal_softplus(mean_params, std_params, d): \n",
    "    means = mean_params\n",
    "    stds = 1e-3 + tf.math.softplus(0.05 * std_params)\n",
    "    return tfd.MultivariateNormalTriL(loc=means, scale_tril=tfp.math.fill_triangular(stds))\n",
    "\n",
    "def multivariate_diagonal_normal_softplus(mean_params, std_params, d): \n",
    "    means = mean_params\n",
    "    stds = 1e-3 + tf.math.softplus(0.05 * std_params)\n",
    "    return tfd.MultivariateNormalDiag(loc=means, scale_diag=stds)\n",
    "\n",
    "def flatten_dataframe(df, features, output_feature, date_col):\n",
    "    df['turbine_id'] = df['turbine']\n",
    "    df = df.pivot(index=date_col, columns='turbine_id', values=features + [output_feature])\n",
    "    df.columns = ['_'.join(map(str, col)).strip() for col in df.columns.values]\n",
    "    return df\n",
    "\n",
    "def train_multivariate_model(model, X_train, y_train, epochs, batch_size, patience, cp_callback):\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "\n",
    "    model.build(X_train.shape)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=[early_stopping, cp_callback]\n",
    "    )\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0a71f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to ensure that each model has repeatable results,we fix the seed both for the\n",
    "# data splitting part and for the initilialization of the networks' weights. Theoretially\n",
    "# speaking, we should average over different seeds to ensure the robustness of our results.\n",
    "# However, in practice, due to the size of the data set this is unfeasibile and we only do\n",
    "# this for the best performing model to show that the variability of results based on seed\n",
    "# is almost none.\n",
    "\n",
    "keras.utils.set_random_seed(812)\n",
    "MODELS_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9394bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Cleaned_data.pkl'\n",
    "df_full = pd.read_pickle(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c8211e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime column\n",
    "DATETIME_COL = 'Date.time'\n",
    "\n",
    "units = {\n",
    "'Wind.speed.me': 'm/s',\n",
    "'Wind.speed.sd': 'm/s', \n",
    "'Wind.speed.min': 'm/s',\n",
    "'Wind.speed.max': 'm/s',\n",
    "'Front.bearing.temp.me': '°C',\n",
    "'Front.bearing.temp.sd': '°C',\n",
    "'Front.bearing.temp.min': '°C',\n",
    "'Front.bearing.temp.max': '°C',\n",
    "'Rear.bearing.temp.me': '°C',\n",
    "'Rear.bearing.temp.sd': '°C',\n",
    "'Rear.bearing.temp.min': '°C',\n",
    "'Rear.bearing.temp.max': '°C',\n",
    "'Rotor.bearing.temp.me': '°C',\n",
    "'Stator1.temp.me': '°C',\n",
    "'Nacelle.ambient.temp.me': '°C',\n",
    "'Nacelle.temp.me': '°C',\n",
    "'Transformer.temp.me': '°C',\n",
    "'Gear.oil.temp.me': '°C',\n",
    "'Gear.oil.inlet.temp.me': '°C',\n",
    "'Top.box.temp.me': '°C',\n",
    "'Hub.temp.me': '°C',\n",
    "'Conv.Amb.temp.me': '°C',\n",
    "'Rotor.bearing.temp.me': '°C',\n",
    "'Transformer.cell.temp.me': '°C',\n",
    "'Motor.axis1.temp.me': '°C',\n",
    "'Motor.axis2.temp.me': '°C',\n",
    "'CPU.temp.me': '°C',\n",
    "'Blade.ang.pitch.pos.A.me': '°',\n",
    "'Blade.ang.pitch.pos.B.me': '°',\n",
    "'Blade.ang.pitch.pos.C.me': '°',\n",
    "'Gear.oil.inlet.press.me': 'bar',\n",
    "'Gear.oil.pump.press.me': 'bar',\n",
    "'Drive.train.acceleration.me': 'mm/s^2',\n",
    "'Tower.Acceleration.x': 'mm/s^2',\n",
    "'Tower.Acceleration.y': 'mm/s^2'\n",
    "}\n",
    "\n",
    "# Features considered\n",
    "features = [\n",
    "'Wind.speed.me',\n",
    "'Wind.speed.sd',\n",
    "'Wind.speed.min',\n",
    "'Wind.speed.max',\n",
    "'Front.bearing.temp.me',\n",
    "'Front.bearing.temp.sd',\n",
    "'Front.bearing.temp.min',\n",
    "'Front.bearing.temp.max',\n",
    "'Rear.bearing.temp.me',\n",
    "'Rear.bearing.temp.sd',\n",
    "'Rear.bearing.temp.min',\n",
    "'Rear.bearing.temp.max',\n",
    "'Rotor.bearing.temp.me',\n",
    "'Stator1.temp.me',\n",
    "'Nacelle.ambient.temp.me',\n",
    "'Nacelle.temp.me',\n",
    "'Transformer.temp.me',\n",
    "'Gear.oil.temp.me',\n",
    "'Gear.oil.inlet.temp.me',\n",
    "'Top.box.temp.me',\n",
    "'Hub.temp.me',\n",
    "'Conv.Amb.temp.me',\n",
    "'Rotor.bearing.temp.me',\n",
    "'Transformer.cell.temp.me',\n",
    "'Motor.axis1.temp.me',\n",
    "'Motor.axis2.temp.me',\n",
    "'CPU.temp.me',\n",
    "'Blade.ang.pitch.pos.A.me',\n",
    "'Blade.ang.pitch.pos.B.me',\n",
    "'Blade.ang.pitch.pos.C.me',\n",
    "'Gear.oil.inlet.press.me',\n",
    "'Gear.oil.pump.press.me',\n",
    "'Drive.train.acceleration.me',\n",
    "'Tower.Acceleration.x',\n",
    "'Tower.Acceleration.y'\n",
    "]\n",
    "\n",
    "output_feature = 'Power.me'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d6d55887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set confidence interval to be considered as 'normal behaviour'\n",
    "CONFIDENCE_INTERVAL = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "928f2d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dataframe(df, features, output_feature, date_col):\n",
    "    df['turbine_id'] = df['turbine']\n",
    "    df = df.pivot(index=date_col, columns='turbine_id', values=features + [output_feature])\n",
    "    df.columns = ['_'.join(map(str, col)).strip() for col in df.columns.values]\n",
    "    return df\n",
    "\n",
    "# Only consider the turbine with ID 5\n",
    "TURBINE_ID = 5\n",
    "\n",
    "# Specify the number of turbines to consider\n",
    "turbine_num = 6\n",
    "\n",
    "# Select the two turbines with the most common non-NaN data points\n",
    "turbine_counts = df_full.groupby('turbine').apply(lambda x: x.notna().all(axis=1).sum())\n",
    "turbine_ids = turbine_counts.nlargest(turbine_num).index.tolist()\n",
    "\n",
    "df_top_n = df_full[df_full['turbine'].isin(turbine_ids)]\n",
    "df_multivariate = flatten_dataframe(df_top_n, features, output_feature, DATETIME_COL)\n",
    "df_multivariate.dropna(inplace=True)\n",
    "df_transfer = df_full[['turbine'] + features + [output_feature] + [DATETIME_COL]]\n",
    "df_transfer_grouped = df_transfer.groupby(DATETIME_COL)\n",
    "df_transfer = df_transfer_grouped.filter(lambda group: group.notna().all().all() and len(group) == turbine_num)\n",
    "\n",
    "# Check the data set is of the same size\n",
    "assert df_transfer.shape[0] == df_multivariate.shape[0]*turbine_num\n",
    "df_single_turbine = df_transfer[df_transfer['turbine'] == TURBINE_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e0858cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91326, 38)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turbine</th>\n",
       "      <th>Wind.speed.me</th>\n",
       "      <th>Wind.speed.sd</th>\n",
       "      <th>Wind.speed.min</th>\n",
       "      <th>Wind.speed.max</th>\n",
       "      <th>Front.bearing.temp.me</th>\n",
       "      <th>Front.bearing.temp.sd</th>\n",
       "      <th>Front.bearing.temp.min</th>\n",
       "      <th>Front.bearing.temp.max</th>\n",
       "      <th>Rear.bearing.temp.me</th>\n",
       "      <th>...</th>\n",
       "      <th>Blade.ang.pitch.pos.A.me</th>\n",
       "      <th>Blade.ang.pitch.pos.B.me</th>\n",
       "      <th>Blade.ang.pitch.pos.C.me</th>\n",
       "      <th>Gear.oil.inlet.press.me</th>\n",
       "      <th>Gear.oil.pump.press.me</th>\n",
       "      <th>Drive.train.acceleration.me</th>\n",
       "      <th>Tower.Acceleration.x</th>\n",
       "      <th>Tower.Acceleration.y</th>\n",
       "      <th>Power.me</th>\n",
       "      <th>Date.time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>778652</th>\n",
       "      <td>5</td>\n",
       "      <td>4.758976</td>\n",
       "      <td>0.470051</td>\n",
       "      <td>3.839334</td>\n",
       "      <td>5.655419</td>\n",
       "      <td>66.905266</td>\n",
       "      <td>0.300394</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>67.350006</td>\n",
       "      <td>65.931580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.154892</td>\n",
       "      <td>329.839172</td>\n",
       "      <td>47.446136</td>\n",
       "      <td>34.605957</td>\n",
       "      <td>12.856477</td>\n",
       "      <td>170.785782</td>\n",
       "      <td>2017-09-25 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778653</th>\n",
       "      <td>5</td>\n",
       "      <td>5.053728</td>\n",
       "      <td>0.455439</td>\n",
       "      <td>4.297034</td>\n",
       "      <td>5.879260</td>\n",
       "      <td>66.657501</td>\n",
       "      <td>0.230908</td>\n",
       "      <td>66.300003</td>\n",
       "      <td>67.099998</td>\n",
       "      <td>65.932503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.530861</td>\n",
       "      <td>337.024353</td>\n",
       "      <td>45.788548</td>\n",
       "      <td>24.391794</td>\n",
       "      <td>12.387291</td>\n",
       "      <td>196.361282</td>\n",
       "      <td>2017-09-25 00:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778654</th>\n",
       "      <td>5</td>\n",
       "      <td>4.834767</td>\n",
       "      <td>0.438846</td>\n",
       "      <td>3.727230</td>\n",
       "      <td>5.667759</td>\n",
       "      <td>67.272499</td>\n",
       "      <td>0.084375</td>\n",
       "      <td>67.099998</td>\n",
       "      <td>67.400002</td>\n",
       "      <td>66.452499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.428474</td>\n",
       "      <td>335.595490</td>\n",
       "      <td>44.958530</td>\n",
       "      <td>19.414160</td>\n",
       "      <td>14.047290</td>\n",
       "      <td>213.066101</td>\n",
       "      <td>2017-09-25 00:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778655</th>\n",
       "      <td>5</td>\n",
       "      <td>4.909376</td>\n",
       "      <td>0.403833</td>\n",
       "      <td>3.910666</td>\n",
       "      <td>5.488893</td>\n",
       "      <td>67.349998</td>\n",
       "      <td>0.128452</td>\n",
       "      <td>67.050003</td>\n",
       "      <td>67.550003</td>\n",
       "      <td>66.452499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.759590</td>\n",
       "      <td>318.466614</td>\n",
       "      <td>45.136253</td>\n",
       "      <td>21.682341</td>\n",
       "      <td>11.815598</td>\n",
       "      <td>180.647583</td>\n",
       "      <td>2017-09-25 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778656</th>\n",
       "      <td>5</td>\n",
       "      <td>4.800600</td>\n",
       "      <td>0.485835</td>\n",
       "      <td>4.098299</td>\n",
       "      <td>5.829768</td>\n",
       "      <td>67.722504</td>\n",
       "      <td>0.181987</td>\n",
       "      <td>67.400002</td>\n",
       "      <td>68.050003</td>\n",
       "      <td>66.864998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.908447</td>\n",
       "      <td>320.857849</td>\n",
       "      <td>44.799519</td>\n",
       "      <td>21.100346</td>\n",
       "      <td>11.945602</td>\n",
       "      <td>201.553589</td>\n",
       "      <td>2017-09-25 00:40:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        turbine  Wind.speed.me  Wind.speed.sd  Wind.speed.min  Wind.speed.max  \\\n",
       "778652        5       4.758976       0.470051        3.839334        5.655419   \n",
       "778653        5       5.053728       0.455439        4.297034        5.879260   \n",
       "778654        5       4.834767       0.438846        3.727230        5.667759   \n",
       "778655        5       4.909376       0.403833        3.910666        5.488893   \n",
       "778656        5       4.800600       0.485835        4.098299        5.829768   \n",
       "\n",
       "        Front.bearing.temp.me  Front.bearing.temp.sd  Front.bearing.temp.min  \\\n",
       "778652              66.905266               0.300394               66.500000   \n",
       "778653              66.657501               0.230908               66.300003   \n",
       "778654              67.272499               0.084375               67.099998   \n",
       "778655              67.349998               0.128452               67.050003   \n",
       "778656              67.722504               0.181987               67.400002   \n",
       "\n",
       "        Front.bearing.temp.max  Rear.bearing.temp.me  ...  \\\n",
       "778652               67.350006             65.931580  ...   \n",
       "778653               67.099998             65.932503  ...   \n",
       "778654               67.400002             66.452499  ...   \n",
       "778655               67.550003             66.452499  ...   \n",
       "778656               68.050003             66.864998  ...   \n",
       "\n",
       "        Blade.ang.pitch.pos.A.me  Blade.ang.pitch.pos.B.me  \\\n",
       "778652                       0.0                       0.0   \n",
       "778653                       0.0                       0.0   \n",
       "778654                       0.0                       0.0   \n",
       "778655                       0.0                       0.0   \n",
       "778656                       0.0                       0.0   \n",
       "\n",
       "        Blade.ang.pitch.pos.C.me  Gear.oil.inlet.press.me  \\\n",
       "778652                       0.0                76.154892   \n",
       "778653                       0.0                78.530861   \n",
       "778654                       0.0                78.428474   \n",
       "778655                       0.0                72.759590   \n",
       "778656                       0.0                73.908447   \n",
       "\n",
       "        Gear.oil.pump.press.me  Drive.train.acceleration.me  \\\n",
       "778652              329.839172                    47.446136   \n",
       "778653              337.024353                    45.788548   \n",
       "778654              335.595490                    44.958530   \n",
       "778655              318.466614                    45.136253   \n",
       "778656              320.857849                    44.799519   \n",
       "\n",
       "        Tower.Acceleration.x  Tower.Acceleration.y    Power.me  \\\n",
       "778652             34.605957             12.856477  170.785782   \n",
       "778653             24.391794             12.387291  196.361282   \n",
       "778654             19.414160             14.047290  213.066101   \n",
       "778655             21.682341             11.815598  180.647583   \n",
       "778656             21.100346             11.945602  201.553589   \n",
       "\n",
       "                 Date.time  \n",
       "778652 2017-09-25 00:00:00  \n",
       "778653 2017-09-25 00:10:00  \n",
       "778654 2017-09-25 00:20:00  \n",
       "778655 2017-09-25 00:30:00  \n",
       "778656 2017-09-25 00:40:00  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_single_turbine.shape)\n",
    "df_single_turbine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7453770c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(547956, 38)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turbine</th>\n",
       "      <th>Wind.speed.me</th>\n",
       "      <th>Wind.speed.sd</th>\n",
       "      <th>Wind.speed.min</th>\n",
       "      <th>Wind.speed.max</th>\n",
       "      <th>Front.bearing.temp.me</th>\n",
       "      <th>Front.bearing.temp.sd</th>\n",
       "      <th>Front.bearing.temp.min</th>\n",
       "      <th>Front.bearing.temp.max</th>\n",
       "      <th>Rear.bearing.temp.me</th>\n",
       "      <th>...</th>\n",
       "      <th>Blade.ang.pitch.pos.A.me</th>\n",
       "      <th>Blade.ang.pitch.pos.B.me</th>\n",
       "      <th>Blade.ang.pitch.pos.C.me</th>\n",
       "      <th>Gear.oil.inlet.press.me</th>\n",
       "      <th>Gear.oil.pump.press.me</th>\n",
       "      <th>Drive.train.acceleration.me</th>\n",
       "      <th>Tower.Acceleration.x</th>\n",
       "      <th>Tower.Acceleration.y</th>\n",
       "      <th>Power.me</th>\n",
       "      <th>Date.time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.171129</td>\n",
       "      <td>0.390980</td>\n",
       "      <td>4.240140</td>\n",
       "      <td>5.912565</td>\n",
       "      <td>67.665001</td>\n",
       "      <td>0.194358</td>\n",
       "      <td>67.350006</td>\n",
       "      <td>68.099998</td>\n",
       "      <td>67.337502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.076599</td>\n",
       "      <td>355.346771</td>\n",
       "      <td>44.632309</td>\n",
       "      <td>22.022369</td>\n",
       "      <td>14.627177</td>\n",
       "      <td>200.121521</td>\n",
       "      <td>2017-09-25 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.090679</td>\n",
       "      <td>0.436131</td>\n",
       "      <td>4.303428</td>\n",
       "      <td>5.930200</td>\n",
       "      <td>67.764999</td>\n",
       "      <td>0.137932</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>67.527496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.719238</td>\n",
       "      <td>353.837952</td>\n",
       "      <td>43.258904</td>\n",
       "      <td>20.714163</td>\n",
       "      <td>10.469490</td>\n",
       "      <td>196.931503</td>\n",
       "      <td>2017-09-25 00:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5.193162</td>\n",
       "      <td>0.305424</td>\n",
       "      <td>4.739578</td>\n",
       "      <td>5.894996</td>\n",
       "      <td>67.639999</td>\n",
       "      <td>0.095655</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>67.800003</td>\n",
       "      <td>67.495003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.778137</td>\n",
       "      <td>353.752502</td>\n",
       "      <td>41.394890</td>\n",
       "      <td>23.446747</td>\n",
       "      <td>11.127916</td>\n",
       "      <td>197.651825</td>\n",
       "      <td>2017-09-25 00:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4.995740</td>\n",
       "      <td>0.258361</td>\n",
       "      <td>4.488607</td>\n",
       "      <td>5.601314</td>\n",
       "      <td>67.477501</td>\n",
       "      <td>0.104252</td>\n",
       "      <td>67.350006</td>\n",
       "      <td>67.699997</td>\n",
       "      <td>67.467499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.186005</td>\n",
       "      <td>348.852203</td>\n",
       "      <td>43.366161</td>\n",
       "      <td>18.103645</td>\n",
       "      <td>11.582632</td>\n",
       "      <td>182.931046</td>\n",
       "      <td>2017-09-25 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5.111104</td>\n",
       "      <td>0.296016</td>\n",
       "      <td>4.674517</td>\n",
       "      <td>5.677069</td>\n",
       "      <td>67.792496</td>\n",
       "      <td>0.174840</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>68.099998</td>\n",
       "      <td>67.822502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.173264</td>\n",
       "      <td>351.041290</td>\n",
       "      <td>41.450455</td>\n",
       "      <td>19.340059</td>\n",
       "      <td>12.164517</td>\n",
       "      <td>202.370926</td>\n",
       "      <td>2017-09-25 00:40:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   turbine  Wind.speed.me  Wind.speed.sd  Wind.speed.min  Wind.speed.max  \\\n",
       "0        1       5.171129       0.390980        4.240140        5.912565   \n",
       "1        1       5.090679       0.436131        4.303428        5.930200   \n",
       "2        1       5.193162       0.305424        4.739578        5.894996   \n",
       "3        1       4.995740       0.258361        4.488607        5.601314   \n",
       "4        1       5.111104       0.296016        4.674517        5.677069   \n",
       "\n",
       "   Front.bearing.temp.me  Front.bearing.temp.sd  Front.bearing.temp.min  \\\n",
       "0              67.665001               0.194358               67.350006   \n",
       "1              67.764999               0.137932               67.500000   \n",
       "2              67.639999               0.095655               67.500000   \n",
       "3              67.477501               0.104252               67.350006   \n",
       "4              67.792496               0.174840               67.500000   \n",
       "\n",
       "   Front.bearing.temp.max  Rear.bearing.temp.me  ...  \\\n",
       "0               68.099998             67.337502  ...   \n",
       "1               68.000000             67.527496  ...   \n",
       "2               67.800003             67.495003  ...   \n",
       "3               67.699997             67.467499  ...   \n",
       "4               68.099998             67.822502  ...   \n",
       "\n",
       "   Blade.ang.pitch.pos.A.me  Blade.ang.pitch.pos.B.me  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   Blade.ang.pitch.pos.C.me  Gear.oil.inlet.press.me  Gear.oil.pump.press.me  \\\n",
       "0                       0.0                80.076599              355.346771   \n",
       "1                       0.0                79.719238              353.837952   \n",
       "2                       0.0                79.778137              353.752502   \n",
       "3                       0.0                78.186005              348.852203   \n",
       "4                       0.0                79.173264              351.041290   \n",
       "\n",
       "   Drive.train.acceleration.me  Tower.Acceleration.x  Tower.Acceleration.y  \\\n",
       "0                    44.632309             22.022369             14.627177   \n",
       "1                    43.258904             20.714163             10.469490   \n",
       "2                    41.394890             23.446747             11.127916   \n",
       "3                    43.366161             18.103645             11.582632   \n",
       "4                    41.450455             19.340059             12.164517   \n",
       "\n",
       "     Power.me           Date.time  \n",
       "0  200.121521 2017-09-25 00:00:00  \n",
       "1  196.931503 2017-09-25 00:10:00  \n",
       "2  197.651825 2017-09-25 00:20:00  \n",
       "3  182.931046 2017-09-25 00:30:00  \n",
       "4  202.370926 2017-09-25 00:40:00  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_transfer.shape)\n",
    "df_transfer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3889adf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test_full, y_train_full, y_test_full, scaler_full = load_dataset_train_test_split(df_transfer, features, output_feature)\n",
    "X_train_single_turbine, X_test_single_turbine, y_train_single_turbine, y_test_single_turbine, scaler_single_turbine = load_dataset_train_test_split(df_single_turbine, features, output_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "83a62256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 37)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               11400     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      " distribution_lambda (Distr  ((None, 1),               0         \n",
      " ibutionLambda)               (None, 1))                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91902 (358.99 KB)\n",
      "Trainable params: 91902 (358.99 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the file path for saving the weights\n",
    "checkpoint_path = '/content/drive/My Drive/Colab Notebooks/initial_model_weights_reduced_data.h5'\n",
    "\n",
    "# Define the initial model architecture\n",
    "def generic_model(X_train_full):\n",
    "    inputs = Input(shape=(X_train_full.shape[1],))\n",
    "    hidden1 = Dense(300, activation=\"relu\")(inputs)\n",
    "    hidden2 = Dense(200, activation=\"relu\")(hidden1)\n",
    "    hidden3 = Dense(100, activation=\"relu\")(hidden2)\n",
    "\n",
    "    params = Dense(2)(hidden3)\n",
    "\n",
    "    dist = tfp.layers.DistributionLambda(normal_softplus)(params)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=dist)\n",
    "    model.compile(Adam(learning_rate=0.001), loss=NLL)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Train the initial model using X_full with the checkpoint callback\n",
    "generic_model = generic_model(X_train_full)\n",
    "generic_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0cf5bce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "6165/6165 [==============================] - 29s 4ms/step - loss: 1475.4855 - val_loss: 5.7685\n",
      "Epoch 2/500\n",
      "6165/6165 [==============================] - 27s 4ms/step - loss: 5.2114 - val_loss: 4.9079\n",
      "Epoch 3/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 4.7843 - val_loss: 4.6565\n",
      "Epoch 4/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 4.6350 - val_loss: 4.5187\n",
      "Epoch 5/500\n",
      "6165/6165 [==============================] - 27s 4ms/step - loss: 4.5160 - val_loss: 4.4973\n",
      "Epoch 6/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 4.4310 - val_loss: 4.4558\n",
      "Epoch 7/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 4.3704 - val_loss: 4.3697\n",
      "Epoch 8/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 4.3199 - val_loss: 4.3794\n",
      "Epoch 9/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 4.2672 - val_loss: 4.2685\n",
      "Epoch 10/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 4.2250 - val_loss: 4.1987\n",
      "Epoch 11/500\n",
      "6165/6165 [==============================] - 27s 4ms/step - loss: 4.1884 - val_loss: 4.1590\n",
      "Epoch 12/500\n",
      "6165/6165 [==============================] - 27s 4ms/step - loss: 4.1630 - val_loss: 4.1247\n",
      "Epoch 13/500\n",
      "6165/6165 [==============================] - 27s 4ms/step - loss: 4.1365 - val_loss: 4.1080\n",
      "Epoch 14/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 4.1133 - val_loss: 4.1384\n",
      "Epoch 15/500\n",
      "6165/6165 [==============================] - 24s 4ms/step - loss: 4.0959 - val_loss: 4.0763\n",
      "Epoch 16/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 4.0744 - val_loss: 4.0659\n",
      "Epoch 17/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 4.0611 - val_loss: 4.0216\n",
      "Epoch 18/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 4.0564 - val_loss: 4.0884\n",
      "Epoch 19/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 4.0363 - val_loss: 4.0708\n",
      "Epoch 20/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 4.0257 - val_loss: 4.1181\n",
      "Epoch 21/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 4.0135 - val_loss: 4.0215\n",
      "Epoch 22/500\n",
      "6165/6165 [==============================] - 27s 4ms/step - loss: 4.0030 - val_loss: 4.1926\n",
      "Epoch 23/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.9957 - val_loss: 4.0280\n",
      "Epoch 24/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.9840 - val_loss: 4.0418\n",
      "Epoch 25/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 3.9746 - val_loss: 4.0393\n",
      "Epoch 26/500\n",
      "6165/6165 [==============================] - 27s 4ms/step - loss: 3.9678 - val_loss: 3.9631\n",
      "Epoch 27/500\n",
      "6165/6165 [==============================] - 27s 4ms/step - loss: 3.9632 - val_loss: 4.0560\n",
      "Epoch 28/500\n",
      "6165/6165 [==============================] - 27s 4ms/step - loss: 3.9548 - val_loss: 3.9828\n",
      "Epoch 29/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.9484 - val_loss: 3.9763\n",
      "Epoch 30/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.9423 - val_loss: 3.9784\n",
      "Epoch 31/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.9477 - val_loss: 3.9711\n",
      "Epoch 32/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 3.9294 - val_loss: 3.9957\n",
      "Epoch 33/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.9282 - val_loss: 4.0677\n",
      "Epoch 34/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.9212 - val_loss: 3.9864\n",
      "Epoch 35/500\n",
      "6165/6165 [==============================] - 27s 4ms/step - loss: 3.9201 - val_loss: 3.9301\n",
      "Epoch 36/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.9124 - val_loss: 3.9433\n",
      "Epoch 37/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 3.9083 - val_loss: 3.9746\n",
      "Epoch 38/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.9037 - val_loss: 3.9966\n",
      "Epoch 39/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.8981 - val_loss: 3.9159\n",
      "Epoch 40/500\n",
      "6165/6165 [==============================] - 27s 4ms/step - loss: 3.9001 - val_loss: 3.9115\n",
      "Epoch 41/500\n",
      "6165/6165 [==============================] - 28s 5ms/step - loss: 3.8920 - val_loss: 3.9307\n",
      "Epoch 42/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.8864 - val_loss: 3.9124\n",
      "Epoch 43/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.8874 - val_loss: 3.9111\n",
      "Epoch 44/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.8829 - val_loss: 3.9178\n",
      "Epoch 45/500\n",
      "6165/6165 [==============================] - 30s 5ms/step - loss: 3.8816 - val_loss: 3.9219\n",
      "Epoch 46/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.8770 - val_loss: 3.9413\n",
      "Epoch 47/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.8710 - val_loss: 3.9220\n",
      "Epoch 48/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.8687 - val_loss: 3.9450\n",
      "Epoch 49/500\n",
      "6165/6165 [==============================] - 27s 4ms/step - loss: 3.8777 - val_loss: 3.9196\n",
      "Epoch 50/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.8633 - val_loss: 3.8959\n",
      "Epoch 51/500\n",
      "6165/6165 [==============================] - 27s 4ms/step - loss: 3.8601 - val_loss: 3.8908\n",
      "Epoch 52/500\n",
      "6165/6165 [==============================] - 28s 4ms/step - loss: 3.8545 - val_loss: 3.8825\n",
      "Epoch 53/500\n",
      "6165/6165 [==============================] - 27s 4ms/step - loss: 3.8562 - val_loss: 3.9167\n",
      "Epoch 54/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.9671 - val_loss: 3.9251\n",
      "Epoch 55/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.8736 - val_loss: 3.9205\n",
      "Epoch 56/500\n",
      "6165/6165 [==============================] - 27s 4ms/step - loss: 3.8526 - val_loss: 3.9706\n",
      "Epoch 57/500\n",
      "6165/6165 [==============================] - 28s 4ms/step - loss: 3.8538 - val_loss: 3.9012\n",
      "Epoch 58/500\n",
      "6165/6165 [==============================] - 29s 5ms/step - loss: 3.8481 - val_loss: 3.9041\n",
      "Epoch 59/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.8420 - val_loss: 3.8830\n",
      "Epoch 60/500\n",
      "6165/6165 [==============================] - 27s 4ms/step - loss: 3.8402 - val_loss: 3.8985\n",
      "Epoch 61/500\n",
      "6165/6165 [==============================] - 27s 4ms/step - loss: 3.8435 - val_loss: 3.9350\n",
      "Epoch 62/500\n",
      "6165/6165 [==============================] - 28s 5ms/step - loss: 3.8425 - val_loss: 3.9461\n",
      "Epoch 63/500\n",
      "6165/6165 [==============================] - 29s 5ms/step - loss: 3.8379 - val_loss: 3.9045\n",
      "Epoch 64/500\n",
      "6165/6165 [==============================] - 28s 4ms/step - loss: 3.8646 - val_loss: 3.9187\n",
      "Epoch 65/500\n",
      "6165/6165 [==============================] - 27s 4ms/step - loss: 3.8323 - val_loss: 3.9113\n",
      "Epoch 66/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.8411 - val_loss: 3.8907\n",
      "Epoch 67/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.8252 - val_loss: 3.8982\n",
      "Epoch 68/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.8248 - val_loss: 3.8797\n",
      "Epoch 69/500\n",
      "6165/6165 [==============================] - 27s 4ms/step - loss: 3.8221 - val_loss: 3.9344\n",
      "Epoch 70/500\n",
      "6165/6165 [==============================] - 28s 4ms/step - loss: 3.8196 - val_loss: 3.8702\n",
      "Epoch 71/500\n",
      "6165/6165 [==============================] - 28s 5ms/step - loss: 3.8162 - val_loss: 3.9025\n",
      "Epoch 72/500\n",
      "6165/6165 [==============================] - 27s 4ms/step - loss: 3.8151 - val_loss: 3.8798\n",
      "Epoch 73/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.8151 - val_loss: 4.0368\n",
      "Epoch 74/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 3.8121 - val_loss: 3.8671\n",
      "Epoch 75/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 3.8067 - val_loss: 3.8782\n",
      "Epoch 76/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 3.8065 - val_loss: 3.8768\n",
      "Epoch 77/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 3.8051 - val_loss: 3.8707\n",
      "Epoch 78/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 3.8063 - val_loss: 3.8808\n",
      "Epoch 79/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6165/6165 [==============================] - 24s 4ms/step - loss: 3.8021 - val_loss: 3.8626\n",
      "Epoch 80/500\n",
      "6165/6165 [==============================] - 24s 4ms/step - loss: 3.7979 - val_loss: 3.8950\n",
      "Epoch 81/500\n",
      "6165/6165 [==============================] - 24s 4ms/step - loss: 3.8026 - val_loss: 3.9099\n",
      "Epoch 82/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.7962 - val_loss: 3.8946\n",
      "Epoch 83/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 3.7956 - val_loss: 3.9172\n",
      "Epoch 84/500\n",
      "6165/6165 [==============================] - 27s 4ms/step - loss: 3.7951 - val_loss: 3.8833\n",
      "Epoch 85/500\n",
      "6165/6165 [==============================] - 29s 5ms/step - loss: 3.7919 - val_loss: 3.9086\n",
      "Epoch 86/500\n",
      "6165/6165 [==============================] - 31s 5ms/step - loss: 3.7909 - val_loss: 3.9066\n",
      "Epoch 87/500\n",
      "6165/6165 [==============================] - 30s 5ms/step - loss: 3.7878 - val_loss: 3.8979\n",
      "Epoch 88/500\n",
      "6165/6165 [==============================] - 30s 5ms/step - loss: 3.7875 - val_loss: 3.9688\n",
      "Epoch 89/500\n",
      "6165/6165 [==============================] - 31s 5ms/step - loss: 3.7844 - val_loss: 3.8917\n",
      "Epoch 90/500\n",
      "6165/6165 [==============================] - 31s 5ms/step - loss: 3.7853 - val_loss: 3.8933\n",
      "Epoch 91/500\n",
      "6165/6165 [==============================] - 32s 5ms/step - loss: 3.7845 - val_loss: 3.8827\n",
      "Epoch 92/500\n",
      "6165/6165 [==============================] - 33s 5ms/step - loss: 3.8024 - val_loss: 3.8929\n",
      "Epoch 93/500\n",
      "6165/6165 [==============================] - 34s 6ms/step - loss: 3.7835 - val_loss: 3.8865\n",
      "Epoch 94/500\n",
      "6165/6165 [==============================] - 32s 5ms/step - loss: 3.7791 - val_loss: 3.8632\n",
      "Epoch 95/500\n",
      "6165/6165 [==============================] - 35s 6ms/step - loss: 3.7781 - val_loss: 3.9738\n",
      "Epoch 96/500\n",
      "6165/6165 [==============================] - 33s 5ms/step - loss: 3.7764 - val_loss: 3.9148\n",
      "Epoch 97/500\n",
      "6165/6165 [==============================] - 34s 5ms/step - loss: 3.7793 - val_loss: 3.8554\n",
      "Epoch 98/500\n",
      "6165/6165 [==============================] - 33s 5ms/step - loss: 3.7761 - val_loss: 3.8861\n",
      "Epoch 99/500\n",
      "6165/6165 [==============================] - 36s 6ms/step - loss: 3.7758 - val_loss: 3.8432\n",
      "Epoch 100/500\n",
      "6165/6165 [==============================] - 31s 5ms/step - loss: 3.7717 - val_loss: 3.8603\n",
      "Epoch 101/500\n",
      "6165/6165 [==============================] - 30s 5ms/step - loss: 3.7710 - val_loss: 3.9055\n",
      "Epoch 102/500\n",
      "6165/6165 [==============================] - 32s 5ms/step - loss: 3.7713 - val_loss: 3.8573\n",
      "Epoch 103/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 3.7701 - val_loss: 3.9151\n",
      "Epoch 104/500\n",
      "6165/6165 [==============================] - 22s 4ms/step - loss: 3.7666 - val_loss: 3.8846\n",
      "Epoch 105/500\n",
      "6165/6165 [==============================] - 22s 4ms/step - loss: 3.7665 - val_loss: 3.8691\n",
      "Epoch 106/500\n",
      "6165/6165 [==============================] - 23s 4ms/step - loss: 3.7734 - val_loss: 3.9046\n",
      "Epoch 107/500\n",
      "6165/6165 [==============================] - 23s 4ms/step - loss: 3.7679 - val_loss: 3.8838\n",
      "Epoch 108/500\n",
      "6165/6165 [==============================] - 30s 5ms/step - loss: 3.7673 - val_loss: 3.8689\n",
      "Epoch 109/500\n",
      "6165/6165 [==============================] - 24s 4ms/step - loss: 3.7704 - val_loss: 3.8734\n",
      "Epoch 110/500\n",
      "6165/6165 [==============================] - 24s 4ms/step - loss: 3.7677 - val_loss: 3.9011\n",
      "Epoch 111/500\n",
      "6165/6165 [==============================] - 22s 4ms/step - loss: 3.7625 - val_loss: 3.8800\n",
      "Epoch 112/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.7583 - val_loss: 3.8595\n",
      "Epoch 113/500\n",
      "6165/6165 [==============================] - 23s 4ms/step - loss: 3.7575 - val_loss: 3.9406\n",
      "Epoch 114/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 3.7574 - val_loss: 3.9202\n",
      "Epoch 115/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.7526 - val_loss: 3.9040\n",
      "Epoch 116/500\n",
      "6165/6165 [==============================] - 23s 4ms/step - loss: 3.7548 - val_loss: 3.8665\n",
      "Epoch 117/500\n",
      "6165/6165 [==============================] - 22s 4ms/step - loss: 3.7521 - val_loss: 3.8758\n",
      "Epoch 118/500\n",
      "6165/6165 [==============================] - 23s 4ms/step - loss: 3.7519 - val_loss: 3.8823\n",
      "Epoch 119/500\n",
      "6165/6165 [==============================] - 22s 4ms/step - loss: 3.7505 - val_loss: 3.9355\n",
      "Epoch 120/500\n",
      "6165/6165 [==============================] - 22s 4ms/step - loss: 3.7480 - val_loss: 3.8797\n",
      "Epoch 121/500\n",
      "6165/6165 [==============================] - 23s 4ms/step - loss: 3.7480 - val_loss: 3.8630\n",
      "Epoch 122/500\n",
      "6165/6165 [==============================] - 24s 4ms/step - loss: 3.7549 - val_loss: 3.8912\n",
      "Epoch 123/500\n",
      "6165/6165 [==============================] - 23s 4ms/step - loss: 3.7451 - val_loss: 3.9805\n",
      "Epoch 124/500\n",
      "6165/6165 [==============================] - 22s 4ms/step - loss: 3.7466 - val_loss: 3.8887\n",
      "Epoch 125/500\n",
      "6165/6165 [==============================] - 24s 4ms/step - loss: 3.7448 - val_loss: 3.8426\n",
      "Epoch 126/500\n",
      "6165/6165 [==============================] - 24s 4ms/step - loss: 3.7448 - val_loss: 3.8687\n",
      "Epoch 127/500\n",
      "6165/6165 [==============================] - 23s 4ms/step - loss: 3.7430 - val_loss: 5.0711\n",
      "Epoch 128/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 3.7442 - val_loss: 31.3920\n",
      "Epoch 129/500\n",
      "6165/6165 [==============================] - 23s 4ms/step - loss: 3.7418 - val_loss: 3.8935\n",
      "Epoch 130/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 3.7413 - val_loss: 3.8885\n",
      "Epoch 131/500\n",
      "6165/6165 [==============================] - 23s 4ms/step - loss: 3.8452 - val_loss: 3.8464\n",
      "Epoch 132/500\n",
      "6165/6165 [==============================] - 22s 4ms/step - loss: 3.7605 - val_loss: 3.8761\n",
      "Epoch 133/500\n",
      "6165/6165 [==============================] - 22s 3ms/step - loss: 3.7446 - val_loss: 3.8562\n",
      "Epoch 134/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 3.7415 - val_loss: 3.9500\n",
      "Epoch 135/500\n",
      "6165/6165 [==============================] - 22s 4ms/step - loss: 3.7423 - val_loss: 3.8596\n",
      "Epoch 136/500\n",
      "6165/6165 [==============================] - 23s 4ms/step - loss: 3.7386 - val_loss: 3.8759\n",
      "Epoch 137/500\n",
      "6165/6165 [==============================] - 24s 4ms/step - loss: 3.7351 - val_loss: 3.8687\n",
      "Epoch 138/500\n",
      "6165/6165 [==============================] - 23s 4ms/step - loss: 3.7340 - val_loss: 3.8968\n",
      "Epoch 139/500\n",
      "6165/6165 [==============================] - 23s 4ms/step - loss: 3.7393 - val_loss: 4.2817\n",
      "Epoch 140/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 3.7323 - val_loss: 3.9254\n",
      "Epoch 141/500\n",
      "6165/6165 [==============================] - 26s 4ms/step - loss: 3.7307 - val_loss: 3.8619\n",
      "Epoch 142/500\n",
      "6165/6165 [==============================] - 25s 4ms/step - loss: 3.7317 - val_loss: 3.8617\n",
      "Epoch 143/500\n",
      "6165/6165 [==============================] - 24s 4ms/step - loss: 3.7290 - val_loss: 3.8947\n",
      "Epoch 144/500\n",
      "6165/6165 [==============================] - 22s 4ms/step - loss: 3.7276 - val_loss: 23.5438\n",
      "Epoch 145/500\n",
      "6165/6165 [==============================] - 24s 4ms/step - loss: 3.7288 - val_loss: 4.0500\n",
      "Epoch 146/500\n",
      "6165/6165 [==============================] - 24s 4ms/step - loss: 3.7305 - val_loss: 3.8716\n",
      "Epoch 147/500\n",
      "6165/6165 [==============================] - 23s 4ms/step - loss: 3.7283 - val_loss: 3.9239\n",
      "Epoch 148/500\n",
      "6165/6165 [==============================] - 22s 4ms/step - loss: 3.7538 - val_loss: 3.8533\n",
      "Epoch 149/500\n",
      "6165/6165 [==============================] - 22s 4ms/step - loss: 3.7296 - val_loss: 3.8748\n",
      "Epoch 150/500\n",
      "6165/6165 [==============================] - 23s 4ms/step - loss: 3.7246 - val_loss: 7.6204\n",
      "Epoch 151/500\n",
      "6165/6165 [==============================] - 22s 4ms/step - loss: 3.7298 - val_loss: 3.8835\n",
      "Epoch 152/500\n",
      "6165/6165 [==============================] - 23s 4ms/step - loss: 3.7239 - val_loss: 3.9029\n",
      "Epoch 153/500\n",
      "6165/6165 [==============================] - 23s 4ms/step - loss: 3.7258 - val_loss: 229.2005\n",
      "Epoch 154/500\n",
      "6165/6165 [==============================] - 22s 4ms/step - loss: 3.7247 - val_loss: 3.9644\n",
      "Epoch 155/500\n",
      "6165/6165 [==============================] - 22s 3ms/step - loss: 3.7236 - val_loss: 8.0144\n"
     ]
    }
   ],
   "source": [
    "# Define the callback to save the weights\n",
    "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True,\n",
    "                                      monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "history = generic_model.fit(X_train_full, y_train_full, epochs=500, batch_size=64,\n",
    "                            validation_split=0.1, callbacks=[checkpoint_callback, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "019e4cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3425/3425 [==============================] - 7s 2ms/step - loss: 3.8865\n",
      "Evaluation Loss: 3.886470317840576\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Load the weights of the initial model\n",
    "generic_model.load_weights(checkpoint_path)\n",
    "evaluation = generic_model.evaluate(X_test_full, y_test_full)\n",
    "print(\"Evaluation Loss:\", evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "254f1a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer = generic_model.layers[-2].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "49989c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 37)]                 0         []                            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 300)                  11400     ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 200)                  60200     ['dense[1][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 100)                  20100     ['dense_1[1][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 100)                  10100     ['dense_2[1][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 80)                   8080      ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 40)                   3240      ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 20)                   820       ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 20)                   820       ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 10)                   210       ['dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 10)                   210       ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 1)                    11        ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 1)                    11        ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 2)                    0         ['dense_9[0][0]',             \n",
      "                                                                     'dense_12[0][0]']            \n",
      "                                                                                                  \n",
      " distribution_lambda_1 (Dis  ((None, 1),                  0         ['concatenate[0][0]']         \n",
      " tributionLambda)             (None, 1))                                                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 115202 (450.01 KB)\n",
      "Trainable params: 23502 (91.80 KB)\n",
      "Non-trainable params: 91700 (358.20 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model_finetune(X_train, generic_model, seed):\n",
    "    keras.utils.set_random_seed(seed)\n",
    "\n",
    "    inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "    # Step 1: Load the architecture and weights of the previously trained model\n",
    "    pretrained_model_layers = generic_model.layers[1:-2]\n",
    "    x = inputs\n",
    "\n",
    "    for layer in pretrained_model_layers:\n",
    "        layer.trainable = False\n",
    "        x = layer(x)\n",
    "\n",
    "    hidden1 = Dense(100, activation=\"relu\")(x)\n",
    "    hidden2 = Dense(80, activation=\"relu\")(hidden1)\n",
    "    hidden3 = Dense(40, activation=\"relu\")(hidden2)\n",
    "\n",
    "    mean_h1 = Dense(20, activation=\"relu\")(hidden3)\n",
    "    mean_h2 = Dense(10, activation=\"relu\")(mean_h1)\n",
    "    mean_out = Dense(1)(mean_h2)\n",
    "\n",
    "    variance_h1 = Dense(20, activation=\"relu\")(hidden3)\n",
    "    variance_h2 = Dense(10, activation=\"relu\")(variance_h1)\n",
    "    variance_out = Dense(1)(variance_h2)\n",
    "\n",
    "    params = Concatenate()([mean_out, variance_out])\n",
    "\n",
    "\n",
    "    dist = tfp.layers.DistributionLambda(normal_softplus)(params)\n",
    "\n",
    "    model_mlp_gaussian = Model(inputs=inputs, outputs=dist)\n",
    "    model_mlp_gaussian.compile(Adam(learning_rate=0.001), loss=NLL)\n",
    "\n",
    "    return model_mlp_gaussian\n",
    "\n",
    "model_finetune = create_model_finetune(X_train_single_turbine, generic_model, MODELS_SEED)\n",
    "model_finetune.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "99a385b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2055/2055 [==============================] - 11s 4ms/step - loss: 83.2328 - val_loss: 4.0898\n",
      "Epoch 2/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 4.0205 - val_loss: 3.9738\n",
      "Epoch 3/200\n",
      "2055/2055 [==============================] - 7s 4ms/step - loss: 4.0004 - val_loss: 3.9561\n",
      "Epoch 4/200\n",
      "2055/2055 [==============================] - 9s 4ms/step - loss: 3.9922 - val_loss: 3.9411\n",
      "Epoch 5/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.9736 - val_loss: 4.0019\n",
      "Epoch 6/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.9726 - val_loss: 4.0168\n",
      "Epoch 7/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.9714 - val_loss: 3.9125\n",
      "Epoch 8/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.9801 - val_loss: 3.9189\n",
      "Epoch 9/200\n",
      "2055/2055 [==============================] - 7s 3ms/step - loss: 3.9792 - val_loss: 3.9274\n",
      "Epoch 10/200\n",
      "2055/2055 [==============================] - 7s 4ms/step - loss: 3.9549 - val_loss: 3.9363\n",
      "Epoch 11/200\n",
      "2055/2055 [==============================] - 7s 4ms/step - loss: 3.9631 - val_loss: 3.9097\n",
      "Epoch 12/200\n",
      "2055/2055 [==============================] - 7s 4ms/step - loss: 3.9385 - val_loss: 3.9202\n",
      "Epoch 13/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.9414 - val_loss: 3.8990\n",
      "Epoch 14/200\n",
      "2055/2055 [==============================] - 7s 4ms/step - loss: 3.9272 - val_loss: 3.9014\n",
      "Epoch 15/200\n",
      "2055/2055 [==============================] - 7s 4ms/step - loss: 3.9258 - val_loss: 3.9874\n",
      "Epoch 16/200\n",
      "2055/2055 [==============================] - 7s 4ms/step - loss: 3.9275 - val_loss: 3.9113\n",
      "Epoch 17/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.9208 - val_loss: 3.9016\n",
      "Epoch 18/200\n",
      "2055/2055 [==============================] - 7s 3ms/step - loss: 3.9118 - val_loss: 3.8937\n",
      "Epoch 19/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.9046 - val_loss: 3.9749\n",
      "Epoch 20/200\n",
      "2055/2055 [==============================] - 7s 3ms/step - loss: 3.9071 - val_loss: 3.8926\n",
      "Epoch 21/200\n",
      "2055/2055 [==============================] - 7s 4ms/step - loss: 3.9003 - val_loss: 3.9180\n",
      "Epoch 22/200\n",
      "2055/2055 [==============================] - 7s 3ms/step - loss: 3.8947 - val_loss: 3.8782\n",
      "Epoch 23/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8865 - val_loss: 3.8892\n",
      "Epoch 24/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8887 - val_loss: 3.8984\n",
      "Epoch 25/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8861 - val_loss: 3.8993\n",
      "Epoch 26/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8858 - val_loss: 3.8860\n",
      "Epoch 27/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8945 - val_loss: 3.8843\n",
      "Epoch 28/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8788 - val_loss: 3.8849\n",
      "Epoch 29/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8731 - val_loss: 3.8995\n",
      "Epoch 30/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8752 - val_loss: 3.9140\n",
      "Epoch 31/200\n",
      "2055/2055 [==============================] - 7s 4ms/step - loss: 3.8663 - val_loss: 3.8876\n",
      "Epoch 32/200\n",
      "2055/2055 [==============================] - 7s 3ms/step - loss: 3.8659 - val_loss: 4.2044\n",
      "Epoch 33/200\n",
      "2055/2055 [==============================] - 7s 3ms/step - loss: 3.8663 - val_loss: 3.8821\n",
      "Epoch 34/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8636 - val_loss: 3.8913\n",
      "Epoch 35/200\n",
      "2055/2055 [==============================] - 7s 3ms/step - loss: 3.8530 - val_loss: 3.9417\n",
      "Epoch 36/200\n",
      "2055/2055 [==============================] - 7s 3ms/step - loss: 3.8588 - val_loss: 3.9492\n",
      "Epoch 37/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8563 - val_loss: 3.9092\n",
      "Epoch 38/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8571 - val_loss: 4.1387\n",
      "Epoch 39/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8489 - val_loss: 3.8805\n",
      "Epoch 40/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8537 - val_loss: 4.0435\n",
      "Epoch 41/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8473 - val_loss: 3.8804\n",
      "Epoch 42/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8431 - val_loss: 3.9051\n",
      "Epoch 43/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8520 - val_loss: 3.8831\n",
      "Epoch 44/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8437 - val_loss: 4.0421\n",
      "Epoch 45/200\n",
      "2055/2055 [==============================] - 10s 5ms/step - loss: 3.8493 - val_loss: 3.8935\n",
      "Epoch 46/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8353 - val_loss: 3.8896\n",
      "Epoch 47/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8352 - val_loss: 3.8921\n",
      "Epoch 48/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8372 - val_loss: 3.9010\n",
      "Epoch 49/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8343 - val_loss: 3.8960\n",
      "Epoch 50/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8340 - val_loss: 3.8978\n",
      "Epoch 51/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8304 - val_loss: 3.9113\n",
      "Epoch 52/200\n",
      "2055/2055 [==============================] - 8s 4ms/step - loss: 3.8331 - val_loss: 3.9486\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABUQUlEQVR4nO2dd3hUZfbHPycdCDUUgdCrNEEQ6yrYFcW1rfizobv2gm1t61pQV93V1bWuvawFK4iIFUVULHSUphBAekkoARLSzu+P914ySWaSSTKTMpzP88wzd+59773vnUzu957znvccUVUMwzAMozRxtd0BwzAMo25iAmEYhmEExQTCMAzDCIoJhGEYhhEUEwjDMAwjKCYQhmEYRlBMIIyoIyIfi8gFkW5bm4jIChE5OgrHnSoif/GWzxGRz8JpW4XzdBSRHSISX9W+GrGPCYQRFO/m4b+KRCQn4PM5lTmWqp6gqq9Eum1dRERuEZFpQda3FJE8EekX7rFU9XVVPTZC/SohaKr6u6qmqmphJI5f6lwqIt0jfVyj5jGBMILi3TxSVTUV+B04OWDd6347EUmovV7WSV4DDhGRLqXWjwJ+VtVfaqFPhlElTCCMSiEiw0RktYjcLCLrgZdEpLmITBKRTSKyxVtOD9gn0G0yWkS+FZGHvLbLReSEKrbtIiLTRCRbRL4QkSdF5LUQ/Q6nj/eIyHfe8T4TkZYB288TkZUikikifwv1/ajqauBL4LxSm84HXq2oH6X6PFpEvg34fIyILBaRbSLyBCAB27qJyJde/zaLyOsi0szb9j+gI/ChZwHeJCKdvSf9BK9NOxGZKCJZIrJURC4OOPZdIvK2iLzqfTcLRGRIqO8gFCLS1DvGJu+7vF1E4rxt3UXka+/aNovIW956EZFHRGSjiGwXkZ8rY4UZ1cMEwqgK+wAtgE7AJbjf0Uve545ADvBEOfsfCCwBWgL/BF4QEalC2zeAn4A04C7K3pQDCaeP/wdcCLQGkoAbAUSkD/C0d/x23vmC3tQ9Xgnsi4j0AgZ6/a3sd+UfoyXwPnA77rtYBhwa2AS43+vfvkAH3HeCqp5HSSvwn0FOMQ5Y7e1/BvAPETkyYPtIr00zYGI4fQ7C40BToCtwBE40L/S23QN8BjTHfbePe+uPBQ4Henr7/gnIrMK5jaqgqvayV7kvYAVwtLc8DMgDUsppPxDYEvB5KvAXb3k0sDRgW0NAgX0q0xZ3cy0AGgZsfw14LcxrCtbH2wM+XwF84i3fAYwL2NbI+w6ODnHshsB24BDv833AB1X8rr71ls8HfghoJ7gb+l9CHPePwJxgf0Pvc2fvu0zAiUkh0Dhg+/3Ay97yXcAXAdv6ADnlfLcKdC+1Lt77zvoErLsUmOotvwo8C6SX2u9I4FfgICCutv8X9raXWRBGVdikqrn+BxFpKCLPeG6D7cA0oJmEjpBZ7y+o6i5vMbWSbdsBWQHrAFaF6nCYfVwfsLwroE/tAo+tqjsp5ynW69M7wPmetXMO7gZYle/Kp3QfNPCziLQRkXEissY77ms4SyMc/O8yO2DdSqB9wOfS302KVG78qSWQ6B032DluwoneT54L6yIAVf0SZ608CWwUkWdFpEklzmtUAxMIoyqUTgF8A9ALOFBVm+BcAhDgI48C64AWItIwYF2HctpXp4/rAo/tnTOtgn1ewblDjgEaAx9Wsx+l+yCUvN5/4P4u/b3jnlvqmOWlbV6L+y4bB6zrCKypoE+VYTOQj3OtlTmHqq5X1YtVtR3OsnhKvEgoVX1MVQfjLJeewF8j2C+jHEwgjEjQGOdL3yoiLYA7o31CVV0JzATuEpEkETkYODlKfXwXOElEDhORJGAsFf/vfANsxblNxqlqXjX78RHQV0RO857cr8G52nwaAzuAbSLSnrI30Q04338ZVHUVMB24X0RSRGQA8GecFVJVkrxjpYhIirfubeA+EWksIp2A6/1ziMiZAYP1W3CCViQiB4jIgSKSCOwEcoGiavTLqAQmEEYkeBRogHtK/AH4pIbOew5wMM7dcy/wFrA7RNtHqWIfVXUBcCVukHkd7ga2uoJ9FOdW6uS9V6sfqroZOBN4AHe9PYDvAprcDewPbMOJyfulDnE/cLuIbBWRG4Oc4mzcuMRaYDxwp6p+EU7fQrAAJ4T+60LgatxNPgP4Fvd9vui1PwD4UUR24AbBx6hqBtAEeA73na/EXfu/qtEvoxKINxBkGPUeLzRysapG3YIxjL0BsyCMeovnfugmInEicjxwCjChlrtlGDGDzYI16jP74FwpaTiXz+WqOqd2u2QYsYO5mAzDMIygmIvJMAzDCErMuJhatmypnTt3ru1uGIZh1CtmzZq1WVVbBdsWMwLRuXNnZs6cWdvdMAzDqFeIyMpQ28zFZBiGYQTFBMIwDMMIigmEYRiGEZSYGYMwDKPmyM/PZ/Xq1eTm5lbc2KgTpKSkkJ6eTmJiYtj7mEAYhlFpVq9eTePGjencuTOhaz0ZdQVVJTMzk9WrV9OlS+lquKExF5NhGJUmNzeXtLQ0E4d6goiQlpZWaYvPBMIwjCph4lC/qMrfK+oCISLxIjJHRCYF2Xa9iCwUkfkiMsXLEe9vu0BEfvNeF0S7n4YRc2zcCO+XzvptGOFTExbEGGBRiG1zgCGqOgBXlOWfAAGFVA4EhgJ3ikjzGuirYcQOL70EZ5wBO3fWdk8iTmZmJgMHDmTgwIHss88+tG/ffs/nvLy8cvedOXMm11xzTYXnOOSQQyLS16lTp3LSSSdF5Fg1TVQHqb0KUSNwRduvL71dVb8K+PgDrkwiwHHA56qa5R3nc+B44M1o9tcwYorsbFCFXbugUaPa7k1ESUtLY+7cuQDcddddpKamcuONxXWQCgoKSEgIfnsbMmQIQ4YMqfAc06dPj0hf6zPRtiAexRUjD6dE4J+Bj73l9pQsQL+akgXUDcOoiJycku8xzujRo7nssss48MADuemmm/jpp584+OCDGTRoEIcccghLliwBSj7R33XXXVx00UUMGzaMrl278thjj+05Xmpq6p72w4YN44wzzqB3796cc845+FmwJ0+eTO/evRk8eDDXXHNNpSyFN998k/79+9OvXz9uvvlmAAoLCxk9ejT9+vWjf//+PPLIIwA89thj9OnThwEDBjBq1Kjqf1lhEjULQkROAjaq6iwRGVZB23OBIcARlTzHJcAlAB07dqxaRw0jVqkhgbj7wwUsXLs9osfs064Jd57ct9L7rV69munTpxMfH8/27dv55ptvSEhI4IsvvuC2227jvffeK7PP4sWL+eqrr8jOzqZXr15cfvnlZeYKzJkzhwULFtCuXTsOPfRQvvvuO4YMGcKll17KtGnT6NKlC2effXbY/Vy7di0333wzs2bNonnz5hx77LFMmDCBDh06sGbNGn755RcAtm7dCsADDzzA8uXLSU5O3rOuJoimBXEoMFJEVgDjgCNFpEwRdBE5GvgbMFJV/XrCa4AOAc3SvXUlUNVnVXWIqg5p1SpoMkLD2HvZtcu97yUWBMCZZ55JfHw8ANu2bePMM8+kX79+XHfddSxYsCDoPiNGjCA5OZmWLVvSunVrNmzYUKbN0KFDSU9PJy4ujoEDB7JixQoWL15M165d98wrqIxAzJgxg2HDhtGqVSsSEhI455xzmDZtGl27diUjI4Orr76aTz75hCZNmgAwYMAAzjnnHF577bWQrrNoELUzqeqtwK0AngVxo6qeG9hGRAYBzwDHq+rGgE2fAv8IGJg+1j+WYRhhUkMWRFWe9KNFo4Cxlr///e8MHz6c8ePHs2LFCoYNGxZ0n+Tk5D3L8fHxFBQUVKlNJGjevDnz5s3j008/5b///S9vv/02L774Ih999BHTpk3jww8/5L777uPnn3+uEaGo8XkQIjJWREZ6H/8FpALviMhcEZkI4A1O3wPM8F5j/QFrwzDCZC8bgyjNtm3baN/eDV2+/PLLET9+r169yMjIYMWKFQC89dZbYe87dOhQvv76azZv3kxhYSFvvvkmRxxxBJs3b6aoqIjTTz+de++9l9mzZ1NUVMSqVasYPnw4Dz74INu2bWPHjh0Rv55g1IitoqpTgane8h0B648uZ58XgRej3TfDiFl8F5P/vpdx0003ccEFF3DvvfcyYsSIiB+/QYMGPPXUUxx//PE0atSIAw44IGTbKVOmkJ6evufzO++8wwMPPMDw4cNRVUaMGMEpp5zCvHnzuPDCCykqcnE9999/P4WFhZx77rls27YNVeWaa66hWbNmEb+eYMRMTeohQ4aoFQwyjAAOPRSmT4e334Yzz4zooRctWsS+++4b0WPWR3bs2EFqaiqqypVXXkmPHj247rrrartbIQn2dxORWaoaNO7XUm0YRqyyl7uYaoLnnnuOgQMH0rdvX7Zt28all15a212KKJbN1TBilb0wiqmmue666+q0xVBdzIIwjFjFLAijmphAGEasYgJhVBMTCMOIVUwgjGpiAmEYsYifpA/22jBXo/qYQBhGLJKfD14sfSxaEMOHD+fTTz8tse7RRx/l8ssvD7nPsGHD8EPhTzzxxKA5je666y4eeuihcs89YcIEFi5cuOfzHXfcwRdffFGJ3genLqYFN4EwjFgkUBRiUCDOPvtsxo0bV2LduHHjws6HNHny5CpPNistEGPHjuXoo0PO+a3XmEAYRiwS6FaKQYE444wz+Oijj/YUB1qxYgVr167lD3/4A5dffjlDhgyhb9++3HnnnUH379y5M5s3bwbgvvvuo2fPnhx22GF7UoKDm+NwwAEHsN9++3H66aeza9cupk+fzsSJE/nrX//KwIEDWbZsGaNHj+bdd98F3IzpQYMG0b9/fy666CJ2796953x33nkn+++/P/3792fx4sVhX2ttpgW3eRCGEYvUpAVx7bXgFe+JGAMHwqOPhtzcokULhg4dyscff8wpp5zCuHHj+NOf/oSIcN9999GiRQsKCws56qijmD9/PgMGDAh6nFmzZjFu3Djmzp1LQUEB+++/P4MHDwbgtNNO4+KLLwbg9ttv54UXXuDqq69m5MiRnHTSSZxxxhkljpWbm8vo0aOZMmUKPXv25Pzzz+fpp5/m2muvBaBly5bMnj2bp556ioceeojnn3++wq+httOCmwVhGLFIjLuYoKSbKdC99Pbbb7P//vszaNAgFixYUMIdVJpvvvmGU089lYYNG9KkSRNGjhy5Z9svv/zCH/7wB/r378/rr78eMl24z5IlS+jSpQs9e/YE4IILLmDatGl7tp922mkADB48eE+Cv4qo7bTgZkEYRixSky6mcp70o8kpp5zCddddx+zZs9m1axeDBw9m+fLlPPTQQ8yYMYPmzZszevRocnNzq3T80aNHM2HCBPbbbz9efvllpk6dWq3++inDI5EuvKbSgpsFYRixiC8KSUkxG+aamprK8OHDueiii/ZYD9u3b6dRo0Y0bdqUDRs28PHHH5d7jMMPP5wJEyaQk5NDdnY2H3744Z5t2dnZtG3blvz8fF5//fU96xs3bkx2dnaZY/Xq1YsVK1awdOlSAP73v/9xxBGVKpJZhtpOC24WhGHEIr5ApKXFrIsJnJvp1FNP3eNq2m+//Rg0aBC9e/emQ4cOHHrooeXuv//++3PWWWex33770bp16xIpu++55x4OPPBAWrVqxYEHHrhHFEaNGsXFF1/MY489tmdwGiAlJYWXXnqJM888k4KCAg444AAuu+yySl1PXUsLbum+DSMWmTABTj0V+vZ1FkRGRkQPb+m+6yeW7tswjGK3UoxbEEZ0MYEwjFjEF4UWLUwgjCoTdYEQkXgRmSMik4JsO1xEZotIgYicUWpboVenek+tasMwwqQGxiBixT29t1CVv1dNDFKPARYBTYJs+x0YDdwYZFuOqg6MXrcMI4YJdDHl5UFhIcTHR+zwKSkpZGZmkpaWhohE7LhGdFBVMjMzSUlJqdR+URUIEUkHRgD3AdeX3q6qK7x2RdHsh2HsdfhWQ/PmxZ9TUyN2+PT0dFavXs2mTZsidkwjuqSkpJSIkAqHaFsQjwI3AY2rsG+KiMwECoAHVHVC6QYicglwCUDHjh2r3kvDiDVyctwcCF8UIiwQiYmJdOnSJWLHM+omURuDEJGTgI2qOquKh+jkhV79H/CoiHQr3UBVn1XVIao6pFWrVtXprmHEFrt2QYMG7gU2UG1UiWgOUh8KjBSRFcA44EgReS3cnVV1jfeeAUwFBkWhj4YRm+TkOHFo2LD4s2FUkqgJhKreqqrpqtoZGAV8qarnhrOviDQXkWRvuSVObEJn3DIMoyQ5OU4czIIwqkGNz4MQkbEiMtJbPkBEVgNnAs+IiJ8ucV9gpojMA77CjUGYQBhGuPgWhAmEUQ1qJBeTqk7FuYlQ1TsC1s8Aygyrq+p0oH9N9M0wYpLSYxB1JWHfTTfB0UfDscfWdk+MMLCZ1IYRi9RVC+Kxx+CDD2q7F0aYmEAYRixSF8cg8vNh926oZgpqo+YwgTCMWKQuhrn6NRR27qzdfhhhYwJhGLFIXQxz9QXCLIh6gwmEYcQiddHFZBZEvcMEwjBiEXMxGRHABMIwYhHfxZSUBCJ1I8zVdy2Zi6neYAJhGLFGUZGLFmrY0IlDgwZmQRhVwgTCMGKN3Fz37ruX6ppAmAVRbzCBMIxYw3cn1VWB2LkTrBpdvcAEwjBiDV8M/BDXhg3rlkAUFjoXmFHnMYEwjFjDF4O6akGAjUPUE0wgDCPWCOZiqgtRTCYQ9Q4TCMOINeqqBRE4OG0D1fUCEwjDiDVKj0HUFYEwC6LeYQJhGLFGXY9iArMg6gkmEIYRa9RVF1N2NjRr5pbNgqgXRF0gRCReROaIyKQg2w4XkdkiUiAiZ5TadoGI/Oa9Loh2Pw0jZqjLYa777OOWTSDqBTVhQYwBFoXY9jswGngjcKWItADuBA4EhgJ3ikjzKPbRMGKHumxBtG3rls3FVC+IqkCISDowAng+2HZVXaGq84GiUpuOAz5X1SxV3QJ8Dhwfzb4aRsxQV8Ncd+yANm3cslkQ9YJoWxCPAjdRVgAqoj2wKuDzam9dCUTkEhGZKSIzN23aVOVOGkZMESyKKT/fzWCuTQJdTGZB1AuiJhAichKwUVVnRescqvqsqg5R1SGtWrWK1mkMo36Rk+OyuCYluc91oSZEXp57tWwJ8fFmQdQTomlBHAqMFJEVwDjgSBF5Lcx91wAdAj6ne+sMw6gIv1iQiPtcFwTCD3Ft3BhSU82CqCdETSBU9VZVTVfVzsAo4EtVPTfM3T8FjhWR5t7g9LHeOsMwKsIvN+pT1wSiUSOzIOoJNT4PQkTGishIb/kAEVkNnAk8IyILAFQ1C7gHmOG9xnrrDMOoCL+anI8vFiYQRiVJqImTqOpUYKq3fEfA+hk491GwfV4EXqyB7hlGbOG7mHzqmgVhLqZ6g82kNoxYo7QF4S/XZqirLwipqWZB1CNMIAwj1qjrYxBmQdQbTCAMI9YIZUHUFYEwC6LeYAJhGLFGfRiDMIGoF5hAGEasUdddTI0amYupnmACYRixRl0Nc01MhORkczHVI0wgDCPWqIsuph07nGsJ3Htubu3nhjIqxATCMGKNUC6m2gxzzc527iVwFgSYFVEPMIEwjFhCtayLKSnJ5WWqbReTLxC+JWHjEHUeEwjDiCX8tN6BAiFS+0WDzIKol5hAGEYsUboWhI8JhFEFTCAMI5YoXW7Up7brUpuLqV5iAmEYsUTpcqM+dcGC8IXBLIh6gwmEYcQSoSyI2q5LvWOHWRD1EBMIw4glbAzCiCAmEIYRS5RnQdSWQOze7aKrSlsQJhB1HhMIw4gl6uIYRGAeJii2IMzFVOcxgTCMWKIuuphKC4TfN7Mg6jxRFwgRiReROSIyKci2ZBF5S0SWisiPItLZW99ZRHJEZK73+m+0+2kYMUFdDHP1BcJ3LcXFuf6YBVHnqYma1GOARUCTINv+DGxR1e4iMgp4EDjL27ZMVQfWQP8MI3aoiy4mXwh8CwIso2s9IaoWhIikAyOA50M0OQV4xVt+FzhKRCSafTKMmKY8F1NthbmWdjGBlR2tJ0TbxfQocBNQFGJ7e2AVgKoWANuANG9bF8819bWI/CHYziJyiYjMFJGZmzZtimzPDaM+UhejmIIJhFkQ9YKoCYSInARsVNVZVdh9HdBRVQcB1wNviEgZF5WqPquqQ1R1SKtWrarZY8OIAcpzMfmJ/GoaE4h6SzQtiEOBkSKyAhgHHCkir5VqswboACAiCUBTIFNVd6tqJoAnMMuAnlHsq2HEBjk5Lr13fHzJ9bVZNKg6LqbZs2HevOj0y6iQqAmEqt6qqumq2hkYBXypqueWajYRuMBbPsNroyLSSkTiAUSkK9ADyIhWXw0jZihdC8KnrglEuBbEVVfBdddFp18Av/0G118PRaG84Hs3NT4PQkTGishI7+MLQJqILMW5km7x1h8OzBeRubjB68tUNaum+2oY9Y5QAlGbdal37HD1qJOSiteFa0Fs2uRe0eKDD+CRR2DVquidox5TE2GuqOpUYKq3fEfA+lzgzCDt3wPeq4m+GUZMUboetU9tWxCB1gOEb0FkZUFKSnT6BZCZ6d43b4ZOnaJ3nnpKjQiEYRg1ROl61D61WZc6mECkplYsEEVFsGULJCdHr29ZnmNi8+bonaMeY6k2DCOWqKtjEMEsiB07XA3tUGzb5rbn5kav374F4b8bJTCBMIxYoj65mPybfyiysoIvR5JAF5NRhrAEQkQaiUict9xTREaKSGJ0u2YYRqWpyMVUVwQinKJBNSEQ5mIql3AtiGlAioi0Bz4DzgNejlanDMOoInXVxeQLgk84RYPMgqh1whUIUdVdwGnAU6p6JtA3et0yDKNKhHIx1XaYq1kQ9ZKwBUJEDgbOAT7y1sWX094wjNqgvkQx1QULIienWDBNIIISrkBcC9wKjFfVBd7s5q+i1ivDMKpGXXMxqZY/BlGbAhF4TItiCkpY8yBU9WvgawBvsHqzql4TzY7VFKrK5ws3cGDXNJo2sHF3o55T1wRi924oKAhtQZTnYsrMdPvl5kZHIHxRaNrULIgQhBvF9IaINBGRRsAvwEIR+Wt0u1YzLN+8k0tfm8VjU36r7a4YRvUoKnI302AupqQkEKl5gQiWhwnCdzGlpUGLFtG1IHr1cgJR3pyMvZRwXUx9VHU78EfgY6ALLpKp3tO1VSpnDenAK9NXsGxTlAqYrFoFK1dG59iG4ePPKQhmQYjUTk2I0uVGfcIdpG7Rwr2i4QLyj9mzJ+TlWQGjIIQrEInevIc/AhNVNR+IGbm94dhepCTGc99HiyJ/8PXr4cAD4fzzI39swwgkVLEgn9oQiGDlRiF8C8IXiGhbEGBupiCEKxDPACuARsA0EekEbI9Wp2qaVo2TufrI7ny5eCNf/xrBzJEFBTBqFKxbBxmWrdyIMqGKBfk0bFj/XEzRFIhACwJMIIIQlkCo6mOq2l5VT1THSmB4lPtWo4w+tDOd0hpy76SFFBRGKDf8bbfB11/DgAGwdq0TDMOIFqHqUfvURl3qUAKRlORSgIfrYoqWQKSkQIcO7rMJRBnCHaRuKiL/9us/i8jDOGsiZkhOiOdvJ+7Lbxt38PqPv1f/gO+/D//6F1x+OVx5pRtAXL+++sc1jFDURRdTKIGA8lN+q9aMi6lFC2jZ0n22UNcyhOtiehHIBv7kvbYDL0WrU7XFMX3acGj3NB754le27sqr+oF+/RVGj4ahQ10xkvR0t3716oj00zCCUpGLqa4JRHlFg7KzXf3stDT32rnThcxGksxMd2xfIMyCKEO4AtFNVe9U1QzvdTfQNZodqw1EhL+f1IftOfk8+kUVw1537oTTT3cm9DvvuFz2JhBGTRCOi6muRDFB+RaEbzH4FgS42hCRxA+jbdrU1fA2gShDuAKRIyKH+R9E5FAgrF+aiMSLyBwRmRRkW7KIvCUiS0XkRxHpHLDtVm/9EhE5Lsx+Vpve+zTh7KEd+d8PK/ltQ3bldlaFyy6DBQvgjTegY0e33vdxWllDI5rUNxdTeRZEMIGItJspM9MdOy7OCYUJRBnCFYjLgCdFZIWIrACeAC4Nc98xQKj40T8DW1S1O/AI8CCAiPQBRuESAh4PPCUiNZb76fpjetIwKZ57Kxv2+swz8NprMHYsHHts8fpmzdxTnVkQRjSpiwKxY4ezpgPrUftU1oKItED4FgSYQIQg3Cimeaq6HzAAGKCqg4AjK9pPRNKBEcDzIZqcArziLb8LHCUi4q0fp6q7VXU5sBQYGk5fI0FaajJjjurB179u4t1ZlbipP/AAHH64i14KRMS5mUwgjGjij0GEcjHVVphrMOsByi876g8YR0sgVIstCHDjECYQZahURTlV3e7NqAa4PoxdHgVuAkLFjbYHVnnHLgC2AWmB6z1We+tKICKX+JFVmzZFcP4CcP7BnRncqTk3vjOPW9+fz668CkJUs7LcbOkRI5zJWpr0dHMxGdElHAuiNsJcQwmEX3Y0GNG2IHbuhPz8YguiZUuLYgpCdUqOSrkbRU4CNqrqrGqco1xU9VlVHaKqQ1q1ahXRYyclxPHmxQdx+bBujJuxipMe/5Zf1mwLvcPcue594MDg2zt0MAvCiC510cVUkUBU5GJq3jw6AhFooYBZECGojkBUlGrjUGCkN2YxDjhSRF4r1WYN0AFARBKApkBm4HqPdG9djZKUEMfNx/fm9b8cyK7dhZz61Hc8O20ZRUVBLr0igUhPd5PlCguj1V1jb6ciF1NtCUSwCCaoeJC6USMXBdikiYsyiqRA+McKtCAsYV8ZyhUIEckWke1BXtlAu/L2VdVbVTVdVTvjBpy/VNVzSzWbCFzgLZ/htVFv/SgvyqkL0AP4qfKXFxkO6daSj8f8gaN6t+Efkxdz/os/sTG7VLH1OXOgXTto3Tr4QdLTnThs2BD9Dht7Jzk5brwr2IAwOIHIz6/Zh5TqWBD+072IsySibUEUFMD2mMkgFBHKFQhVbayqTYK8GqtqWLUkSiMiY0VkpPfxBSBNRJbixjRu8c67AHgbWAh8AlypqrX66N28URJPn7s/D5zWn1krt3Dl67NLWhJz58KgQaEP4M+FsHEII1r4tSAkhPe3NmpCBCs36pOa6rKo5ueX3RYoEBD5jK6lLQj/3dxMJaiOiylsVHWqqp7kLd+hqhO95VxVPVNVu6vqUFXNCNjnPlXtpqq9VPXjmuhnRYgIo4Z25O5T+jJjxRbemeXd7HNyYNGi0O4lKJ4LYeMQRrQIVY/apzbqUldkQUBwKyKYQETbggATiFLUiEDEGmcOTmdolxbc//FiMnfsdhPjCgvDsyBiTSBuuAE++6y2e2FA6HrUPrVhQdQ3gbBIphKYQFQBEeG+P/Zj5+4C7pu8yI0/QPkWRIsWLnNkLLmYcnLg3/+GV1+t7Z4YELrcqI+/raZCXUPVo/Ypr2hQ4CQ2iLxABA6Cg1kQITCBqCI92jTmksO78v7sNaz7+nsXadGlS+gdRGIv1HX5cve+ZEnt9sNwhCsQNWVB5OY6y7qyFkRgJleftLTIWxCBAmQCERQTiGpw9ZE96NiiIVnf/kTRgAHBJ8gFEmuzqf0iSL/+auGBdYFdu+qWi6m8RH2B60tbELt2ucHr0i6m7duDD2hXhdIC1KQJJCSYQJSiSpFIhiMlMZ6xJ/Wm8+3LmL//nxhY0Q7p6TBtWrlNduUVcPfEhXy2cD3NGibRopF7pXnvAzs049i++0TqEqqHLxDbt7vw3X3qSL/2VuqaBVFeoj4IbUEEzqL28Ze3boVITIotbUGIWD6mIJhAVJNh8dshP5dx+S1ounknXVqWU0cpPR3WrHFmd3zZ3INLN2Zzxeuz+W3jDk4a0I4iVbbszGNV1i7mrtrKlp15FBQpH1x5KPt1aBa9iwqXZcuKl5csMYGobXJyXGLIUNS0QISqR+3jWxClBaL0AHLgclZWZAQiK6s4cMTHZlOXwQSiungzqJe268HfJ/zC//48FAkVh96hg5uMs3EjtG1bYtOEOWu4bfzPpCTG88qFQzm8Z9l/gh27Czjk/ik8NXUpz5w3JNJXUnkyMooHD5csgSOOiPw58vNdoZhQbgqjmIpcTDUd5hquBVHaxVSeBRGpcYjSFgRYPqYg2BhEVhZcdBEsXFi1/efMgcRE/njO0Xy7dDP3TFrEe7NWM3XJRn5Zs43123LJK/ByFQYJdc3NL+TW93/m2rfm0rddEyZf84eg4gCQmpzA6EM68+mCDZWvVRENMjLgsMNcdFa0Bqr//nc48MDoHDvWqGtRTNFwMUVCIIqKykZJgVkQQTALoqAAJk50AvHdd0FdP+Uydy707cvZh/Xg09+28OJ3y4M2a9YwkUO2beAp4JW3v2VTVhNaN0lm3E+rWLhuO5cd0Y0bj+1JQnz5mj360C48981ynv56Gf/+08DK9TWSqDqBOOEEF83066/ROc+MGe5vs3Nn8Q3FCE59G4MINUgdbYHYvt2JRODxwQQiCCYQrVvDf/4D554Ljz8O114b/r6qzoI48UTi44RXLxrKzrxCMnfsZvOO3WzekUfmjjw279jNpuzd7FjtXE+Zi5bxdOIyCouUpg0SeeGCIRy1b5uwTtmiURJnD+3IK9+v4Lqje9KhRTkuhWiybp0LY+zaFXr1gnnzonOepUvde0YG9O8fnXPECvUtislPC1LTFkTpNBs+voupqKjiiMS9BBMIgP/7P3jzTfjb32DkSHfTC4f16914gjeDWkRITU4gNTmBTmlBnna1L9yYzPV9GjLm3hPI3LGbRskJNEqu3J/h4sO78L8fVvDcNxmMPaVfpfaNGH4EU9euLkvt+PEuNDFUoriqkJtbPLFw6VITiIqobxaESPCEfVlZzm0ZeC1Nm7r2kRCIYIPg4ASisBC2bXPJAQ0bgwDcD++//3XupYsvDj+mv6IU38HO482FiI8TWjdJqbQ4ALRt2oBTB7XnrRmr2JS9u9L7RwRfILp1cxZEYWHxukiew/9b+JaEERw/S2t5ApGU5H6DdSWKCYIXDSo9RwHc/2azZpEZRPaPUdqCsIR9ZTCB8ElPh3/9C778Ep4PVSG1FH6Kjf32q9x5IpBu47IjupFXWBRyzCPqLFvmbjadOkHPnm5dpAeqA0XBBKJ8KioWBO7vVZM1IbKzXSqLxMTQbUJZEKUFAiKXbiOYCwssH1MQTCACufhiGDYMbrwxvBnPc+c6F0vTpuGfI0Kzqbu2SuXEfm157fuVbMspO7u0qEh56bvlHP/oNH7PjELUSkaGC9tNSnIWBER+oNoXhZ49TSAqoqJiQT41WZe6vDxMPsGKBgWLMILICUQoC8LSbZTBBCKQuDhnPeTnw+WXV+xqmjOn/AyuwejQwU2WKwpVpjt8Lh/WjezdBbz2w8oS6zduz2X0yzO4+8OFLF6fzdNfR+HmmpFRPFbTrJkb7I+0BfHbb84XPHRoyUl5RlnCsSD87TUZ5lqRQNSmBVF6nMEEogwmEKXp1g3uvRcmTYJx40K3y852T7Xhjj/4pKc7Adq0qVrdBOjXvilH9GzFi98uJyfP1VP6dMF6jnt0Gj8tz+SeP/bjnAM78t6sNWzYnlvB0SpJRob7rnx69YqOi6lHD+jeHX7/3U2YM4JTGYGoSQuiogmOoSyIaApEZqaz+hNKjf+ZQJTBBCIYY8a4yVnXXBP6Ru6HdVbWgohwZbkrh3cnc2ceL01fzq3vz+fS/82iXbMGTLr6MM47qBOXHt6NgqIiXvw2gmMVO3e6CK7AaK9oCUT37k6IVIuzxxplCdfFVNMCEUkLIlIZXUMdPzXVuUxNIPZgAhGM+Hh44QU3oeaii4K7gyobweQT4cJBQ7u0YEin5vzzkyWMm7GKy47oxvgrDqV7a/eP2TGtIScNaMdrP6xk264IZcL0b9SBAtGzpxPTLVsic47du53V0L27e4GNQ5RHXbUgwhmDCBSInBz3CmVBbN1a/ZrawdJsgCXsC0LUBEJEUkTkJxGZJyILROTuIG06icgUEZkvIlNFJD1gW6GIzPVeE6PVz5D07QsPP+xcTQ8+WHb7nDkuaVi7dpU7bhRKj95yQm+GdGrOG385iFtO6E1SQsk/62VHdGNnXiGv/bgyxBEqSWCIq0+kB6qXL3fC7LuYwASiPOqiQJRXj9qndJhrqAgjf52qm6dQHUJZEGD5mEoRTQtiN3Ckqu4HDASOF5GDSrV5CHhVVQcAY4H7A7blqOpA7zUyiv0MzZVXwqhRcPvt8NVXJbfNneush1CJ+ULRsqUzYyNYWW5I5xa8e/khHNwtyFMR0KddE4b1KjlWUS38AePSLiaInJvJF4Pu3d1TXdOmJhDlESsupooEIrBNVQllQYCl2yhF1ARCHf6jQaL3Kh0W1Af40lv+CjglWv2pEiLw3HPOfTJqlJsxDG6Q+ZdfKj/+AC5Sqn37Gi8cdMUwN1bxzqwICFNGhiuwEvhP3LWrG/SLlED89pt7797d/R26dzeBKI9wLYhIhrlu2AB33+3Go4JRGReT78atCYGoyIKobwLx7bcwe3ZUDh3VMQgRiReRucBG4HNV/bFUk3nAad7yqUBjEfGlPUVEZorIDyLyxxDHv8RrM3NTBKKCgpKaCu+9537EZ53lxGHRIpdWorLjDz61UHr0gM7NGdypOc98nUF+YTVDbP0IpkDrKTHRiUQkLYhmzYqf9Lp3t1DX8qjJMFdVeO016NMH7roLnngieJtwopj8BIx+/6MtEIWFbhwjliyIm26CSy6JyqGjKhCqWqiqA4F0YKiIlE4cdCNwhIjMAY4A1gC+D6STqg4B/g94VES6ldoXVX1WVYeo6pBWkSgiEoo+fZwl8e23cOutxTOoq2JBQK2UHhURLj+iG2u25vDR/HXVO9iyZcHzVfXsGVmB8K0HcIK0YkXkSk7GGv4NNtouptWr4eST4bzznFuxf3+YPDl4f4qKwrMgoNjNFG2B2LrViVd5ApGVVf2B8Jpiwwb44Qc4JTrOlxqJYlLVrTgX0vGl1q9V1dNUdRDwt4C2qOoa7z0DmApU8W4cIc4+241JPPwwPPKI+0fs0aNqx/IFIgKT5SrDkb1b07NNKk9PXYZWtYZ0UZEbQA4mEL16OddQJK7rt9+KB6fBLRcUuMgmoyy+VRCtQWpVePZZF7zx1Vfuf+Cbb1yiyzlzXHbfQCpK1OdTumhQtAUiVKI+n7Q09/vdurXq56hJPvzQ/W3qm0CISCsRaeYtNwCOARaXatNSRPw+3Aq86K1vLiLJfhvgUKCKFX0iyMMPu1m98+bBgAGVrx3hk57uXFQ1bMrGxQmXHdGNJRuy+XLxxhLb8gqKmLEiixe/XU7WzrzQB1m71vW9WxmDzgmEH55aHfLyYOXKkgJskUzlE80oppwcOPZYuPRSGDwYfv7ZpcWPj3f1QAA++aTkPuEk6oOyRYOyspy7MljtD3/mcyQEojwLAuqPm+mDD6Bz56hlOo5muu+2wCsiEo8TordVdZKIjAVmqupEYBhwv4goMA240tt3X+AZESny9n1AVWtfIJKT4e23YcgQOPTQqh8nMNS1devI9C1MTt6vHQ9/9itPTV1G0waJfL8skx+WZzJr5RZy892T/+Sf1/HGxQeVCZcFSqb5Lk1gJFPnzlXv5IoV7imutAUBTiCOO67qx45VcnLcjbWih5YGDYozv4b7gPPZZ/DFFy6Z5Q03lBx7GjDAhXpPngwXXli8PlwLonTRIH8AOVh0YEKCC46oThhqeRYK1K+EfTt3ur/LpZdWPpoyTKImEKo6nyBuIVW9I2D5XeDdIG2mA3Uz+X+nTu4mVZGvtzwCJ8vtv39k+hUmifFxXHJ4V+6cuIAz/vs9AL33acyoAzpyUNc0tuXkcfN7P3PnxF/4x6n9y9bXDhbi6hMoENW5iQdGMPnss4/7zs2CCE5FxYJ8AmtChFvn+7vvXGj2VVeVvRGJOCvi3Xed8PiZWyvrYgq0IEI93UP1023EkgXx2WeuZkqU3EtgBYOqRmWytwYjwuk2mDAB3nnH+YjDKMs5amgHcvML6ZTWiAO7tKB5o5JFflZm7uKpqcvo064p5x3UqeTOGRnuybNjx7IHbt3aPeFVd7KcLwKBLiYLdS2fiooF+fgismtX+AIxfbpzLaWkBN9+4oku88D338Phh7t11bUgQlFdgQjXgqgPAvHBB87t9oc/RO0UlmqjNmjd2j1pVTeSKT8f/vpXOPVUeOMNeOWVsHZLTojn0iO6cXy/fcqIA8ANx/biyN6tuXviAn7IKGVqZ2Q4cQiW418kMjmZli51QuP/s/qYQIQmXIGobFW53bth5szyXapHH+3cP4HRTBWVG/UpbUFkZkZXIDIz3e+0WbPg2+uLQBQUuCwPI0aUTToYQUwgaoNITJZbuxaOOgoeeshFVw0ZAo89FpEIovg44dFRA+mY1pArXp/N6i0BcfOhQlx9IiEQfgRTaXdGt25OoOpLCGJNUhUXUzjMnu1E4pBDQrdp0gQOOww+/rh4XWUtiEAXU3kCUd2EfVlZ7qk7VM3phg3dWGNdF4jp053YRdG9BCYQtUd1KstNnerGLmbNgtdfdxOVrr3W3Zg/+ywi3WuSkshz5w8hv7CIS16dxa68ArchsA5EMHr1ctdVOkNnZfDnQJSme3cX4bRmTdWPHatEy4L47jv3Xp5AgHMzzZ9f/NBT2SimmnIxlZdmA9xDSX2YLPfBB25cKMoBGyYQtUVVJssVFcEDDzjLoVkz+OknF4cOcOaZ0LYt/Oc/Eetit1apPHb2IBat385f352Pbt/uMrYGC3H18cqPZs39hbyCKlgz+fkuiinYHBMLdQ1NtARi+nT3927Tpvx2frirb0VUZZB69273Ho5AVNVSrkiAoO4n7FN1AnHUURV/v9XEBKK28AUi3AlrmzfDyJFuJvcZZ8CMGW7Skk9SkquC98knsHhx6ONUkuG9WnPz8b35aP46zr7tTQCeXwv3f7yI/32/gimLNjBhzhr+/dkSrnpjNlfNcpbD3/85nuEPTWXS/LWVm5S3cqVzIYWyIMAEIhjRcDGpOgsinJDuvn1d+HagQKSkVOwfT0hwLp0dO4pTxVckEEVFxQJUWSqyIKDuWxALFzpXb5TdS2BRTLVHhw7uiSkzs+xgbGm+/tpZCps3w+OPuzGHYHHPl17qquE9/jg8+WTEunrp4V1pkpJI4XsuOmmGNOOrb1eQF5DTKU6gQ4uG9OrirIsLW+3mjgaJXPXGHF7tspI7T+5D33ZhRH8FC3H1SU93NxMTiLLk5ISXer4yArFsGWzcWLF7Cdzv8cQTncszLy+8RH0+fkbXiiKMArdlZVUtmjAry6XOKY+WLYvT6dRFPvjAvZ98ctRPZQJRWwSGuoYSiMJCd8MfO9aZ+ZMmlZ//qXVrlxLklVfgvvtCR2pUEhHh/w7sCN86QXjmrrMoatKUTTt2s2ZrDk1SEunYomHxxLr7OzIkdxMfXn0Yb81YxUOfLeHkx79l1NCO3HBMT9JSk0OfLFiIq09cnBv/MIEoS1XCXCti+nT3Hu6k0BNOgGeecTnLwknU5+NndK2sQHTpEt7xA4kFC+KDD1xGh8rWoqkC5mKqLSqqLLdmjfMx3nUXnHOOG5AOJzngmDHun+2FF0K3UXUZaSubjykjw0WANGtGXJzQpkkK+3dsTvfWqSVnXXuRTPFxTli+umEYow/pwtszVjHsoam88ePvod1OS5e6G0aoGebduplABCMnJ/Iupu++c0/pFT1x+xx1lAt//vjjylsQO3ZUXiAqi2/ZhDMGsWWLCyWta6xd68Yea8C9BCYQtUcogVCFt95yqcRnznTWwKuvhv/PNmiQmzjzxBPBw0ELC91YRZ8+bmJdZagoxNXHz+rqiUDThonccXIfPrn2DwxIb8pt43/mhnfmkZsfpH+hQlx9/LTfoQRGtWSFsr2FXbsiP0g9fTocfHDokNDSpKa6iXKTJ9eMi6my+GMcFVkQaWnudxSp8rmRZKJXXNMEIsZp08YN0AWGuv7wgzPnR41yYxSzZsH551f+2GPGuEigDz8suT4319W0eOYZVy71zjsrdzP160BURK9e7gaxYUOJ1d1bN+Z/Fx3IdUf3ZPycNZz+9HRWZZVydSxdWn6W3O7d3c0wVJGap5920VzRqg9SV4l0FNPWrbBgQXjjD4GceKIbRF20KHyBSE2tGQuiojQbPnU5H9MHH7j/wXCtumpiAlFbxMc7H+Lq1e5mPmqUe1pbvty5h2bMKM5tVFlOOcXNdg4Med22zfmI33vPpWqeONHdwP/97/COWVjo+hmOBVFO+dG4OGHM0T144YIh/J61i5Of+JZpv3o384ICd/3BBqh9yotkys93YcA7dsCnn1bcz1ihqMiJfyQF4ocf3FN0ZZNSnniie1+/vmoWRHy8m3gXiupkdA1HgKDuzqbOzoYvv3T/31FKzlcaE4jaJD3dmeO9e7sb9t//7lwsF11U9VTi4CyTq65yE+rmz3f/rMOGucHD115zk+oOOghOPx3++c8yT/pBWb3a3YCrKRA+R/Zuw4dXHcY+TVK44KWfePKrpeiKFU4kqioQ77zjLLL4+OBFbOozqnD11S61Qmn3Wm6uew9nDCIpyd1cKhKI775z3+PQoZXrZ69exZl8q2JBhMrk6pOc7ASlKk/3lbUg6ppAfPKJG0epIfcSmEDULj17uh/tWWe5BHdjx4Yf+VERf/mLu2Hcdpt7Cvz1V+dyOuec4jb/+Ie7uYwdW/HxykvzXZoOHVwM/Lx55Tbr3LIR719xCCcPaMe/Pl3Cv5/2burluZg6dXICWFogVF3akd693TV+8klspeR47DE3rjR5sgt7DiTcWhDgbr7h1KWePh3226/yv0c/3BXC39e3ICrKw+RT1dnU9d2CGD/eiVtl3X7VwASiNnn4YWcxvPJK8aB1pGje3I1ffPSRcy99+SUcf3zJNj17ulq2zz5bPP8gFL5AhDMGERfnzvXUU/Dgg+VGSzVMSuA/owZy18l92LnQTfB7MzOJwqIQ+yQkuCfU0gLx1Vcudv2GG+Ckk9wA44+lS6DXU6ZOddd18snuBvHooyW3V0Yg/HblhbkWFLjvrqo1T3yBqIwF4buYoikQ4VoQ/va6JBBvvw1vvgnnnhvV5HylMYGoTVq0KN+dUl1uucWNbXz7LRx4YPA2d97pzPbbbiv/WBkZ7ocZrpC98YazjG65xVkzeaGr1IkIow/twnWdhNzkBtz6/Sb++OR3/LJmW9D2RV27smvhEmasyCoOl33oITfwf+65cMwxseNm+v13l0alZ083Ce2yy5w70q/LAcU3+3BrlFRUVW7+fHfDruqT6vDhzooMnOlfHoFhruEIRFUT9mVlud9wRcLVsKH7juqKQPz4I1xwgRPsBx6o0VObQMQynTq5p47evUO3adMGbrzRFXwp74l72bJi9044NGjgROLvf4cXX3QWRQVhg41XryS5d0+eOGd/1m/PZeQT33LPpIUs37yTyT+v476PFnL609N5IzOJgt+WcubT0znvhZ9YOfVHF3t/9dXOtdWsmftnqu8CkZMDp53mxHX8eHdju+IKJ36PP16yHVTOgihPIPwEfVW1IBo2dClTzj47vPaNGjmrZf366lsQW7eGnifju7DCGeCtK/mYVq50KXbatXO/gVA1OaJENGtSp4jITyIyT0QWiMjdQdp0EpEpIjJfRKaKSHrAtgtE5DfvdUG0+mng3BetW8NNN4V2B4Ub4hpIXJwb33j1VXfTOeig8ie5LV2KdO/OSQPa8cX1R3D20I688O1yhj80lSten80r368EoPWgvjTZvZN/HN6W+au38tOYv5OX3IDtF/y5+FgnnuhcTmvXVq7PdQVVZy3MmuUCC/yB/3btnGX24ouwfbtbF2mBmD7dWYp+adyqUJkoG3+sYt266gvEhRe6TMfBwpzDtVCgbsym3r7duUt373ZZFFq1qvk+qGpUXoAAqd5yIvAjcFCpNu8AF3jLRwL/85ZbABnee3NvuXl55xs8eLAa1eDJJ1VB9cMPS64vKlJduVK1eXPVyy6r+vG/+UY1LU21RQvVr74quz0/XzUxUfXmm0usnvP7Fn11+nKd8/sW3Z1f6FZ++KHr6/ffa9bSFZqfkKAv73+S7j/2Mx3300otLCxSnT/ftXnhhar3uTZ57DHX/7vvLrttxgy37ZFH3Ocvv3Sfp04N79gHHaR6zDGht3fooHrWWZXucpV57jnX/1DXW5pbbnG/laKikusXLCg+zvXXl91v+HDVQw8Nr0/HHOO+p0iwc6dqQUHl9snPVz3+eNX4eNXPP49MP0IAzNQQ99WoWRDeuf1ZWIneq/TjaR/gS2/5K8CP3zoO+FxVs1R1C/A5UGqE1YgoF1/sooduvtnNIbj3Xmfatm3rXEtbtrgC9VXlsMOcC6tVKzjySFcJzw/PBBeemp9fJoJpYIdmnHdwZwZ2aFacziMg1LX5C8+QUFTEwY/dQ9dWjbj5vZ8Z+eS3TIlvhfphxJGgoMAlrluwwKU6iGaE1Ndfw3XXuXDG228vu33IEOf+efxx1w9/DCISFsSqVe5Vg5EyJaKdwrUg8vPL1hz55z+de+uUU1yyytJZCmraglB1c46aNHEW4OOPhz8x9brrXCTeU0+5in21RSjliMQLiAfmAjuAB4NsfwMY4y2fhhOQNOBG4PaAdn8Hbgyy/yXATGBmx44dIy+texvvvlv8BAaqvXurnn++6hNPqP70U9kntqqwfbvqJZe44/ftqzprllv/2WfhPwXn5qqKqN5wg2qzZqpnnKGqqkVFRTphzmo97MEp2unmSTr5kJM1v1GqFuburnw/FyxQPe441Z49ndUjUvK7OeMM1cLCyh+3IlatUm3dWrVXL9Vt20K3e+cd148JE4qX588P7xwjRqiGsrjHjXPHmjmz8n2vKhMnFn+vr79ecfvnn3dtV64sXvf776oJCapjxqguX+4sjEsvLblferrq6NHh9enqq91vq6ps2+Z+I6B6wgmqBx/slps2Vb3xxpJ999myRfX771VvvdW1veGGqp+/ElCOBRFVgdhzEmiGsxD6lVrfDngfmAP8B1jttQ1LIAJf5mKKAEVFqm+9pfrFF6pbt0b3XJMnq7Zt6/6px45V/c9/3M9x9erw9u/YUbVhQ7fPDz+U2JRXUKjvzFylf7vgHlXQG694VCfOXaMFhWEK3Pjxqqmpqq1aqf7pT6pXXKF6552qjz/ubqD+P/BNN1XqkiskN9e5NVJTVRcuLL9tfr77DoYNU331VdefpUvDO88ZZ6juu2/wbddc477XvLzK9b06TJlSLBAff1xx+/ffd23nzCled+217rfk33ivvNJ9/u234jYNGgR3PQXjrrvcOfLzw76MPfzyixP4+HjVf/2r+MHq++/d7yk+3r3OPNOJ2BFHqLZpU/IB5LTTKu+WqiK1LhCuD9xR3k0eSAVWe8tnA88EbHsGOLu845tA1EMyM1XPPtv9DJOS3D9wuE/lRx7p9jvssJBN8rdu08KERB03bJR2unmSHvXwVJ25Iiv0MQsLnRCA6gEHuKf5YBQVqV5+uWv33/+W280dufl6z4cL9NNf1lV8Tf4x33mn4raqqv/8p2vv77dmTXj7nXeeaufOwbcNHux89TXJjz8W3xh//LHi9lOnurZTprjPmzc7UTv//OI2a9e639M557jPu3a5fe67L7w+PfGEa79hQ+Wu5Y03XF/atAltDa9c6ayIZs3c2N4hh6hedJH7e06cqLpkSWSs9TCpFYEAWgHNvOUGwDfASaXatATivOX7gLHecgtgOW6Aurm33KK885lA1GPeesu5cQ4+OPx9fDfVhAnltzv6aC3q00cnzVurhz4wRbve+pE++vmvml9QSoi2bVMdOdId84ILVHNyyj9ufr7qiSe6J8EQT71L1m/XIx/6SjvdPEl73T5Zf9uwPfTxXn7Znfuvfy3/vIFkZbmbUXKy2zerHPEL5JJL3A2sNNnZ7nr+9rfw+xAJfvmlWCDCsYL8AARfSO++233+5ZeS7W6+2bkGf/7ZWaag+vTT4fXJt1K6dnUW47x5oW/aOTmq06c7a8B/aAlHrIuKalQIQlFbAjHAcx3NB34B7vDWjwVGestnAL8BvwLPA8kB+18ELPVeF1Z0PhOIes7Wre5JMFymTFG98MKKLY6HH3Y/8+XLdVtOno55c7Z2unmSnv7Ud/p75k7XZskS53KJj3fRQ+H+027frjpwoHMJzZ1bYtO7M1dpr9sn6+B7PteJc9fo/mM/0+Me+Vpz8oK4DWbPVk1JcU/ulXVpXHFF8c21IlHzGTNGtUmTkuuKipyrD5z7ryZZsaL4GsIROf9m/8wzqjt2uOi4k08u2y4z013nH/9YLCpvvx1en/LzVV96SfXYY93vAtxv5K67nJXz5pvuexw61I13+P2/7rqadc9FgDrhYor2ywTCCMqiRe5n/tRTe1aNn71a+97xifa74xP95vl33cBhy5aqX32l23Py9MeMTH3x2wy9ffzP+vw3GTprZZbm5ofwB69erdq+vXutWqU5eQV60zvztNPNk/SsZ6brhu3upv3V4g3a6eZJevv4n0vuv3mzc/ekp1fenaGqunixuz6R8IXNDxP12bmz2NV3+ulV87tXh02biq8hHBej7y66//7icODvvgve9h43DqUPPujev/ii8v3buNFZHkccUTJYoUED1cMPd2NR48errgvDjVgHKU8gxG2v/wwZMkRnzpxZ290w6hqqboJf374l6mOsytrFS3f8l78+cxtbWrfj6Zse55u8hqzILM5R1Cgpnp15Lpw1KSGOfu2aMKhjcwZ1bEZao2SSEuJIToij8a8L6TDyOHZ37MRlp93OtLyGXHVUT8Yc1YOE+OJI8n9MXsSz0zL477n7c3y/ti5EdcQIl0fqm28qnznVZ8QINxFx69bw2o8d61Ks5Oe7kNZTT3XpNe67z6VGqaFU0nvwU5W3aBH+7OUGDVwN9vHjXWr7b74J3i472/39c3JciOmcOa4YV1VZuxamTXOpT/r3dxX06jkiMktVhwTdZgJhxDxXXeVmHmdlFacqGD8ePessNnXqwckn/Z2ktq3p27Ypfds1oW/7JvRt15TWjZPZmL2bOb9vYfbvW5m9cgvz12wjr6CozCkOz5jFi+/eTYIWUdigAfG9ernY99693XtyMgVbtvLiJ/PZnbmVCwak0STjNydazzzjkiZWlbVrYfFiN78kHB56yM1Dee89N/+lqMilZCmdzLGmUHUpXLp2rThppE/79m6GcWamm2U8YkToto88Atdf75Z//716M8RjEBMIY+9m8mR3A/nkEzjuOJe6YvRo98Q+eTJFTZoSFxfeU3NeQRG/bsgmO7eAvMIiducXeu9FpP66iIM2LKHpymWuFsaSJa7IUlFZQclPSCShaRPkootcxtuafGp/8kknmgD9+sGECZVPoxJpmjSBffcNPwPvgAHw88+u//Pnl//95ea6CZirVzsrolGjyPQ5RihPIGoub6xh1BbDhjnLYfJkl/zssstcxtEPPoDU1EqlE0hKiKNf+6bBNw5OB44puS431yU6LChwN8HGjZm0PJur3lvIVcO7c+NxVawaWB2aNXPvf/qTq14YqRok1SE1NfxZzlDc9uabKxbXlBRXS+O118LPeGsAJhDG3kDDhk4QXnjBpWcYMcJlr62JzJgpKWXSXp/UsiXTVm7nyalLGdihGUf3aRP9fgRy+uku6d+wYTU/3hCKjh3DK0bl06mTa3/WWeG1P+WUGq3EFiuYi8nYO/DdKmee6Z4kk5JqtTu78gr445Pf8euGHfyhR0vGHNWDIZ0r8QQda2zd6v4m4T7hZ2e7MQi/+ptRZWwMwjDy810SwhNOqF697wiyK6+A135YybPTMti8I49DuqVxzVE9OKhryYpnOXmF/LYxmyXrs2nZOJnhvVrXUo+NWMQEwjDqMDl5hbz+40qemZbBpuzdDO3SggO7tODXDdn8umEHKzJ3EvhvevbQDtx5cl9SEuuG0Bn1GxMIw6gH5OYXMu6n33n662Vsyt5N57RG9NqnMT3bNKb3Po3p0aYx789ezVNTl9G3XROeOmd/OqVZRI5RPUwgDKMeUVBYREGRhrQQpizawPVvz6NIlYfO3I/j+u5Twz00YonyBMJqUhtGHSMhPq5c99FR+7Zh0tWH0aVlIy793yz+MXkR+YVl51oYRnWxMFfDqId0aNGQdy47mHsnufQdH/+yjtaNU0hJjCMlIZ6UpHhSEuJJjBfyCorY7U3m211QSF5BEfFxQv/0phzQqQWDOzWneaPajeoy6ibmYjKMes6k+WuZMGcNOfmF5OYXkZtfSE5+Ibvzi8gvLNqTMyopId57j2N3fiEL120nv9D9/3dvncoBnZtzUNc0ThrQjvgwZ5Yb9R8bgzAMowy5+YXMW7WVmSu3MHNFFrNWbmF7bgEj+rfl32ftR3KCRUntDViqDcMwypCSGM+BXdM40Jt3UVSkPP9tBv+YvJitOXk8c94QUpPtFrE3Y399wzAAiIsTLjm8Gy0aJXPze/P5v+d+4KXRB5CWmlymbWGR8uG8tbzx4++0apzMoI7NGNSxOf3aNzHLI4YwgTAMowRnDE6necNErnh9Nmc+8z2vXjSU9OYuBYYvDI99+RsZm3bStVUj1m7L4aOf1wGQFB9Hn3ZNGNihGQlxwtacfLbuymPrrny27Mpje24BR+/bhttH7Esjs07qPFEbgxCRFGAakIwTondV9c5SbToCrwDNgHjgFlWdLCKdgUXAEq/pD6p6WXnnszEIw4gsM1Zk8eeXZ9AwKYGXLzqAJeuz+c8UJwy992nMtUf34Ng++xAXJ2zcnsucVVuZ/fsW5qzcyvw1W4kToVmDRJo2TKJ5w0SaNUxERJj88zo6pzXi0bMGsl+HZuX2ISevkLg4zCqJIrUySC0iAjRS1R0ikgh8C4xR1R8C2jwLzFHVp0WkDzBZVTt7AjFJVfuFez4TCMOIPIvWbeeCF39iY/ZuAHrv05gxR/XguL77lFtDQ1WREJlif8jI5Lq35rIpezfXHdOTy47oViZqavH67bz6/UrGz15Dg6R4rj26B2cP7UhifNWmbuXmF7J+Wy6dW9rM89LUyiC1V+t0h/cx0XuVViMFmnjLTYG10eqPYRiVZ9+2TXjv8kP49+e/cmyfNhUKg08ocQA4qGsan4w5nNvG/8y/Pl3CtF838chZA2nVOJnPF27glekr+HF5FskJcYzcrx2rt+RwxwcLeHn6Cm49YV+O3rd1uccvzdKNO7j8tVks3bSDK4Z149qje1ZZaPY2ohrmKiLxwCygO/Ckqt5cantb4DOgOdAIOFpVZ3kWxALgV2A7cLuqhig66zALwjDqF6rKu7NWc+fEBSTECQ2TEli/PZf05g0476BO/GlIB5o3SkJVmbJoI//4eBEZm3ZycNc0/jZi39CFmwKY/PM6/vrOPFIS4zmoWxofzV/HoI7NeGzUIDq0CJ5aPDe/kLdmrOKb3zZzzx/70rZpg0hfep2i1udBiEgzYDxwtar+ErD+eq8PD4vIwcALQD+ctZGqqpkiMhiYAPRV1e2ljnsJcAlAx44dB69cuTLq12IYRmRZsXknd05cAMB5B3VieO/WQSfq5RcW8eZPv/PoF7+xZVceJ/ZryxlD0vlD95YklLII8guLePDjxTz/7XIGdWzGU+fsT9umDfhw3lpue/9nAO4/vT8nDWi3Z5+duwt448ffefYbl1U3TqBPuya8c+khNEiK3TGQWhcIrxN3ALtU9aGAdQuA41V1lfc5AzhIVTeW2ncqcKOqhjQRzIIwjL2D7bn5PD11GW/+9Dtbd+XTMjWZUwa249RB7enbrgmbsndz5RuzmbFiC6MP6cxtJ+5LUkKxgKzK2sU14+Yw5/etjDqgA9cf05O3Z67ihW+Xs2VXPod2T+PqI3uwc3cBf3l1JiP6t+XxswdVyq1Vn6itQepWQL6qbhWRBjhX0oOqOimgzcfAW6r6sojsC0wB2gMtgSxVLRSRrsA3QH9VzQp1PhMIw9i7yCso4qslGxk/ew1TFm8gv1Dp2SaVrJ357NxdwAOn9+eUge2D7ptfWMQjn//K018v21Nr48jerblyeHcGd2q+p91/v17GAx8v5oZjenL1UT1q4rJqnNqaSd0WeMUbh4gD3lbVSSIyFpipqhOBG4DnROQ63ID1aFVVETkcGCsi+UARcFl54mAYxt5HUkIcx/Xdh+P67sPWXXlMmr+O8XPW0DApgQdPH0CvfRqH3DcxPo6bju/NYd1bMmXxRk4d1D7omMalh3fl1/XZPPz5r/Ro05jj++1dqdUtF5NhGEY55OYXMurZH1iyPpv3Lj+EPu2aVLxTPcLqQRiGYVSRlMR4nj1vME0bJHLxqzPZvGN3WPtl5+Yza2UWb89cxY8ZmewuKIxyTyOPzXU3DMOogNZNUnju/CGc+cx0Lnl1JqcPTidehLg4IU6E+DgoKoKMzTtYsj6bxeuzWb0lp8QxkhPiGNypOQd3TeOgbmnsl96sxOB5XcRcTIZhGGEyaf5arntr7p46GqWJjxO6tmxE77ZN6L2PqyXepWUjlm7cwQ8ZWXyfkcmidS5aPyUxjlaNk0mKd7U6khLiSI6PIzkxjp5tGnNMnzYM6dS8TAhvadZuzSFrZ15Y80KCUSfCXKONCYRhGDVBdm4+u/IKKVKlsEgpKoJC7z7arllKhXmjtuzM48flmfy0fAtbduW5in8FReQVFpFXUEhOfhGL1m4nr7CI5g0TGd67Ncf22YfDe7YkMT6OhWu3M2vlFmb9voXZK7ewblsuA9KbMvGqw6p0PVYPwjAMI0I0TkmkcUpilfdv3iiJ4/u15fh+bUO22bG7gGm/buLzhRuYsmgj789eQ3JCHCKQm+/qj7dv1oADOruSsYGhuZHEBMIwDKOOkZqcwIn923Ji/7bkFxYxY0UWUxZtRBUGd2rO/p2a1UgKEBMIwzCMOkxifByHdGvJId1a1vi56/YQumEYhlFrmEAYhmEYQTGBMAzDMIJiAmEYhmEExQTCMAzDCIoJhGEYhhEUEwjDMAwjKCYQhmEYRlBiJheTiGwCqlOUuiWwOULdqS/sbde8t10v2DXvLVTnmjupaqtgG2JGIKqLiMwMlbAqVtnbrnlvu16wa95biNY1m4vJMAzDCIoJhGEYhhEUE4hinq3tDtQCe9s1723XC3bNewtRuWYbgzAMwzCCYhaEYRiGERQTCMMwDCMoe71AiMjxIrJERJaKyC213Z9oICIvishGEfklYF0LEflcRH7z3qNTs7CWEJEOIvKViCwUkQUiMsZbH7PXLSIpIvKTiMzzrvlub30XEfnR+42/JSJJtd3XSCIi8SIyR0QmeZ9j+noBRGSFiPwsInNFZKa3LuK/7b1aIEQkHngSOAHoA5wtIn1qt1dR4WXg+FLrbgGmqGoPYIr3OZYoAG5Q1T7AQcCV3t82lq97N3Ckqu4HDASOF5GDgAeBR1S1O7AF+HPtdTEqjAEWBXyO9ev1Ga6qAwPmP0T8t71XCwQwFFiqqhmqmgeMA06p5T5FHFWdBmSVWn0K8Iq3/Arwx5rsU7RR1XWqOttbzsbdQNoTw9etjh3ex0TvpcCRwLve+pi6ZhFJB0YAz3ufhRi+3gqI+G97bxeI9sCqgM+rvXV7A21UdZ23vB5oU5udiSYi0hkYBPxIjF+3526ZC2wEPgeWAVtVtcBrEmu/8UeBm4Ai73MasX29Pgp8JiKzROQSb13Ef9sJ1T2AUf9RVRWRmIx3FpFU4D3gWlXd7h4wHbF43apaCAwUkWbAeKB37fYoeojIScBGVZ0lIsNquTs1zWGqukZEWgOfi8jiwI2R+m3v7RbEGqBDwOd0b93ewAYRaQvgvW+s5f5EHBFJxInD66r6vrc65q8bQFW3Al8BBwPNRMR/GIyl3/ihwEgRWYFzDx8J/IfYvd49qOoa730j7kFgKFH4be/tAjED6OFFPSQBo4CJtdynmmIicIG3fAHwQS32JeJ4vugXgEWq+u+ATTF73SLSyrMcEJEGwDG4sZevgDO8ZjFzzap6q6qmq2pn3P/ul6p6DjF6vT4i0khEGvvLwLHAL0Tht73Xz6QWkRNxfsx44EVVva92exR5RORNYBguJfAG4E5gAvA20BGXJv1Pqlp6ILveIiKHAd8AP1Psn74NNw4Rk9ctIgNwg5PxuIe/t1V1rIh0xT1htwDmAOeq6u7a62nk8VxMN6rqSbF+vd71jfc+JgBvqOp9IpJGhH/be71AGIZhGMHZ211MhmEYRghMIAzDMIygmEAYhmEYQTGBMAzDMIJiAmEYhmEExQTCMCpARAq9rJn+K2IJ/kSkc2CWXcOoS1iqDcOomBxVHVjbnTCMmsYsCMOoIl5O/n96efl/EpHu3vrOIvKliMwXkSki0tFb30ZExnv1GuaJyCHeoeJF5DmvhsNn3ixoROQar57FfBEZV0uXaezFmEAYRsU0KOViOitg2zZV7Q88gZuRD/A48IqqDgBeBx7z1j8GfO3Va9gfWOCt7wE8qap9ga3A6d76W4BB3nEui86lGUZobCa1YVSAiOxQ1dQg61fgCvRkeIkB16tqmohsBtqqar63fp2qthSRTUB6YNoHLxX5516RF0TkZiBRVe8VkU+AHbi0KBMCaj0YRo1gFoRhVA8NsVwZAvMEFVI8NjgCV/Fwf2BGQIZSw6gRTCAMo3qcFfD+vbc8HZddFOAcXNJAcGUgL4c9hX2ahjqoiMQBHVT1K+BmoClQxooxjGhiTySGUTENvCptPp+oqh/q2lxE5uOsgLO9dVcDL4nIX4FNwIXe+jHAsyLyZ5ylcDmwjuDEA695IiLAY16NB8OoMWwMwjCqiDcGMURVN9d2XwwjGpiLyTAMwwiKWRCGYRhGUMyCMAzDMIJiAmEYhmEExQTCMAzDCIoJhGEYhhEUEwjDMAwjKP8PznTPhgOThtsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the callback to save the weights\n",
    "checkpoint_callback = ModelCheckpoint(filepath='saved_models/finetuned_reduced_data.keras', save_weights_only=True,\n",
    "                                      monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "history = model_finetune.fit(X_train_single_turbine, y_train_single_turbine, epochs=200, batch_size=32,\n",
    "                            validation_split=0.1, callbacks=[checkpoint_callback, early_stopping_callback])\n",
    "plot_loss_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c5556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = np.array(model_finetune(X_train_single_turbine).mean()).ravel()\n",
    "y_test_pred = np.array(model_finetune(X_test_single_turbine).mean()).ravel()\n",
    "\n",
    "y_train_stddevs = np.array(model_finetune(X_train_single_turbine).stddev()).ravel()\n",
    "y_test_stddevs = np.array(model_finetune(X_test_single_turbine).stddev()).ravel()\n",
    "\n",
    "evaluate_and_print_metrics({}, f\"Fine Tuned\",\n",
    "y_train_single_turbine, y_test_single_turbine, y_train_pred, y_test_pred,\n",
    "y_train_stddevs, y_test_stddevs, 0.99)\n",
    "\n",
    "plot_means_variances(y_test_single_turbine, y_test_pred, y_test_stddevs)\n",
    "plot_confidence_interval_histogram(y_test_pred, y_test_stddevs, y_test_single_turbine, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b98b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
